---
title: Hierarchies of criteria in IRM
author: ""
date: "`r Sys.Date()`"
output:
  html_document:  
    code_folding: "hide"
    theme: united
    number_sections: no
    toc: yes
    toc_float: true
    toc_depth: 6
    css: js/style.css
params:
  INT: NA
  SYS: comparison
  Agg: 1
  MASK: 1000
  INN1: tester
  RES1: 3
  SOS1: 0
  SUBDIV1: Kebelle
  TRIAD1: Adoption
  TRIBA1: Aptitude
  TRISE1: Feasibility
  INN2: NA
  RES2: 3
  SOS2: 1
  SUBDIV2: Kebelle
  TRIAD2: Adoption
  TRIBA2: Aptitude
  TRISE2: Feasibility

---

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}

div.INN { background-color:#e6f0ff; border-radius: 5px; padding: 10px; font-size: 200%;  color: orange;}
div.Agg { background-color:#e6f0ff; border-radius: 5px; padding: 10px; font-size: 150%;  color: orange;}

</style>

<script src="js/hideOutput.js"></script>

```{r i1_parameter_description, echo=FALSE, message=FALSE, warning=FALSE}

# The parameters above are set to NA here, but when this rmd script is run from the shiny app then the parameters are passed with values.

# The first four parameters are general: 

# INT defines whether interface provides the parameter values - any value other than NA passed from the interface will tell this rmd script to use all parameters. The interface passes a value of 1 automatically.

# SYS is only relevant when more than one innovation is being tested. It sets whether the system is an intercrop, a comparison between crops or a rotation. Allowed values are "comparison","intercrop" and  "rotation"

# Agg defines the aggregation factor. This can be set above in the header with an integer value, or can be passed from the interface. The larger the aggregation factor the quicker the computation. The minimum value is 1.

# MASK defines the spatial resolution of the mask in metres

# The following parameters are specific to each innovation: 

# INN denotes the innovation, this is a unique code for each location/innovation and is used to locate the data and parameters that are used in IRM

# SOS sets whether the season onset is spatially defined. If so, SOS has a value of 1 and the start of the growing period is set using a raster rather than the value in the growth stage csv file. Otherwise SOS is 0.

# RES defines whether 3-class adoption (2 class aptitude), or FAO style 5-class adoption (5-class aptitude with added maps on the limitations) or both classes are computed. Computing both classes will increase the time to run the script!
#A value of 1 will only compute the 3-class suitability maps. A value of 2 will only compute the 5-class suitability map. A value of 3 will compute both suitability class maps. Other classified maps will be shown but only require a re-classification of the other results.

# TRIAD is the field name used for the triangulation points for Adoption

# TRIBA is the field name used for the triangulation points for Biophysical Aptitude

# TRISE is the field name used for the triangulation points for Socio-economic Feasibility

# SUBDIV is the field name used to identify the subdivision polygons


```

```{r i1_folding_outputs_chunks, echo=FALSE, message=FALSE, warning=FALSE}

# Folding outputs chunks

# hideOutput.js and style.css courtesy of Martin Schmelzer https://stackoverflow.com/users/1777111/martin-schmelzer
# https://stackoverflow.com/questions/37755037/how-to-add-code-folding-to-output-chunks-in-rmarkdown-html-documents
 

```

```{r setup, include=FALSE}

# initialisation

library(dplyr)
library(tidyr)
library(data.tree)
library(knitr)
library(kableExtra)
library(here)
library(irm)
library(fuZR)
library(sf)
library(terra)
library(stringr)
library(purrr)
library(tidyterra)
library(tidyverse)
library(scales)
library(tinytex)
library(ggplot2)
library(conflicted)
library(leaflet)
library(tibble)
library(sf)
library(widgetframe)
library(patchwork)
library(here)
library(DiagrammeR)
library(lava)
library(svgPanZoom)
library(scales)
library(lubridate)

```

```{r i1_initialise02, echo=FALSE, message=FALSE, warning=FALSE}

r_filename <- function(filename) {
  here::here("code/r/", filename)
}

source(r_filename("irm_functions.R"))


#set (chunk) options - figure path is necessary to avoid an error message
opts_chunk$set(
  comment = NA,
  dpi = 96,
  echo = FALSE,
  fig.path = paste0("figures/", params$INN1,"/"),
  warning = FALSE,
  cache = FALSE,
  time_it = TRUE,
  include = TRUE
)

options(width = 250, dplyr.width = 120)

knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      # record the current time before each chunk
      now <<- Sys.time()
    } else {
      # calculate the time difference after a chunk
      res <- difftime(Sys.time(), now, units = "secs")
      # return a character string to show the time
      paste("Time for the chunk",
            options$label,
            "to run:",
            round(res,
                  2),
            "seconds")
    }
  }
}))

```

```{r i1_innovation_name1, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

cat("# First Innovation
    ")
```

```{r i1_innovation_name2, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

cat("<div class='INN'>")
cat("Innovation name =", params$INN1)
cat("</div>")
cat("<div class='Agg'>")
cat("Mask Resolution =", params$MASK)
cat("\nSpatial Aggregation =", params$Agg)
cat("</div>")

```

# Basic Settings

## Parameters, Criteria and Rule Bases

Here we load some parameters used in the IRM model, load the table of criteria and their threshold values, weights (if relevant) and data, and display the rule bases in a graphical diagramme. 

### Parameters and Criteria

```{r }

priorities_new_columns_filename <-
  as.character(paste(
    "tab_data/input/priorities_new_columns_",
    params$INN1,
    ".csv",
    sep = ""
  ))

df_priorities <-
  read.csv(here(priorities_new_columns_filename), na.strings = c("NA"))

# remove any rows without data in the rulebase_number or criterion

df_priorities <- df_priorities[complete.cases(df_priorities$rulebase_number, df_priorities$criterion), ]


df_priorities_short <-
  df_priorities %>% select(stack, criterion, weight, threshold, threshold2,	width,	width2)


df_priorities_short$stack[is.na(df_priorities_short$stack)] <-
  "root2"

# Convert to tree
tree_plot <- FromDataFrameNetwork(df_priorities_short, c("weight", "threshold",	"threshold2",	"width",	"width2"
))

# Display the tree
print(tree_plot, "weight", "threshold",	"threshold2",	"width",	"width2", "level")

```

## Get the tree hierarchy for plotting

```{r }

tree_max_level <- max(tree_plot$Get('level')) - 1
cat("\n\nNumber of levels", tree_max_level, "\n\n")

hierarchies_new <- ToDataFrameTree(
  tree_plot,
  level1 = function(x)
    x$path[2],
  level2 = function(x)
    x$path[3],
  level3 = function(x)
    x$path[4],
  level4 = function(x)
    x$path[5],
  level5 = function(x)
    x$path[6],
  level6 = function(x)
    x$path[7],
  level7 = function(x)
    x$path[8],
  
  level_number = function(x)
    x$level - 1
  
)[-1, -1]

# Display the df
hierarchies_new %>% kable(digits = 3, caption = "Hierarchies") %>% kable_styling("striped", full_width = T) %>%  row_spec(0, angle = -45) %>%  scroll_box(height = "500px")

```

## Get the tree leaves for plotting

```{r }

n_leaves <- tree_plot$leafCount
df_leaves <- ToDataFrameTypeCol(tree_plot)

df_leaves_criterion <- as.data.frame( df_leaves[cbind(seq(nrow(df_leaves)), max.col(!is.na(df_leaves), ties.method = 'last'))])
names(df_leaves_criterion) <- c("criterion")
  
df_leaves %>% kable(digits = 3, caption = "Criteria with spatial data") %>% kable_styling("striped", full_width = T) %>%  scroll_box(height = "500px")

```

## Plot the tree graph for plotting

```{r }
# 
SetGraphStyle(
  tree_plot,
  rankdir = "RL",
  overlap = "true",
  fontsize = 400,
  fontname = "Calibri",
  label = paste("Rule bases for",params$INN1),
  labelloc = "t"
)

SetNodeStyle(
  tree_plot,
  shape = "box",
  fontsize = 200,
  fontname = "Helvetica",
  fontcolor = "black",
  fixedsize = "false",
  color = "DarkOliveGreen4",
  fillcolor = "OliveDrab2",
  style = "filled,rounded",
  penwidth = 10,
  tooltip = GetDefaultTooltip
)

SetEdgeStyle(
  tree_plot,
  arrowhead = "none",
  color = "blue",
  penwidth = function(node) (node$weight * 50),
  dir = "back",
  label = function(node) paste("weight = :",node$weight),
  fontsize = 150,
  fontcolor = "blue"
)

level2 <- Traverse(tree_plot, filterFun = function(x) x$level == 2)

Do(level2, function(node)
  SetNodeStyle(
    node,
    shape = "oval",
    fixedsize = "false",
    width = 0.9,
    color = "lightblue",
    fillcolor = "IndianRed3",
    fontsize = 200,
    fontname = "Helvetica",
    fontcolor = "white",
    style = "filled"
  ))

Do(tree_plot$leaves, function(node)
  SetNodeStyle(
    node,
    shape = "oval",
    fixedsize = "false",
    width = 0.9,
    color = "red",
    fillcolor = "IndianRed3",
    fontsize = 200,
    fontname = "Helvetica",
    fontcolor = "white",
    style = "filled"
  ))

plot(tree_plot)

```




```{r}
df_priorities_short <-
  df_priorities %>% select(rulebase_stack, rulebase_number, weight, threshold, threshold2,	width,	width2)


df_priorities_short$rulebase_stack[is.na(df_priorities_short$rulebase_stack)] <-
  "root2"

# Convert to tree
tree_new <- FromDataFrameNetwork(df_priorities_short, c("weight", "threshold",	"threshold2",	"width",	"width2"
))

# Display the tree
print(tree_new, "weight", "threshold",	"threshold2",	"width",	"width2", "level")

```



```{r }
## Get the tree hierarchy

tree_max_level <- max(tree_new$Get('level')) - 1
cat("\n\nNumber of levels", tree_max_level, "\n\n")

hierarchies_new <- ToDataFrameTree(
  tree_new,
  level1 = function(x)
    x$path[2],
  level2 = function(x)
    x$path[3],
  level3 = function(x)
    x$path[4],
  level4 = function(x)
    x$path[5],
  level5 = function(x)
    x$path[6],
  level6 = function(x)
    x$path[7],
  level7 = function(x)
    x$path[8],
  
  level_number = function(x)
    x$level - 1
  
)[-1, -1]

# Display the df
# hierarchies_new %>% kable(digits = 3, caption = "Hierarchies") %>% kable_styling("striped", full_width = T) %>%  row_spec(0, angle = -45) %>%  scroll_box(height = "500px")

```

```{r }
## Get the tree leaves

n_leaves <- tree_new$leafCount
df_leaves <- ToDataFrameTypeCol(tree_new)

df_leaves_criterion <- as.data.frame( df_leaves[cbind(seq(nrow(df_leaves)), max.col(!is.na(df_leaves), ties.method = 'last'))])
names(df_leaves_criterion) <- c("rulebase_number")
  
```



```{r i1_rule_base_stack_binary, results='asis'}

# season onset non-spatial?
if (params$SOS1 != 1){
    nonsos_crit_i1 <- TRUE
} else {nonsos_crit_i1 <- FALSE}

# season onset spatial?
if (params$SOS1 == 1){
    sos_crit_i1 <- TRUE
} else {sos_crit_i1 <- FALSE}

```


# Load Spatial Data

Here we load all the spatial data. The data are used in different chunks below but it is easier to modify file names if all the spatial data are imported in the same chunk.

## Vector Data

The vector data include the sub-divisions of the area that is being modelled, and triangulation points if available.

The vector data are not projected and in geojson format. Here they are loaded and projected to the working crs.

<div class="fold o">   
```{r i1_spatialdataload_vector_01, cache = FALSE, out.width="100%", include = TRUE, echo=FALSE}

wkt_geo <-  paste0( "
  GEOGCRS[\"WGS 84 (with axis order normalized for visualization)\",
          ENSEMBLE[\"World Geodetic System 1984 ensemble\",
                   MEMBER[\"World Geodetic System 1984 (Transit)\",
                          ID[\"EPSG\",1166]],
                   MEMBER[\"World Geodetic System 1984 (G730)\",
                          ID[\"EPSG\",1152]],
                   MEMBER[\"World Geodetic System 1984 (G873)\",
                          ID[\"EPSG\",1153]],
                   MEMBER[\"World Geodetic System 1984 (G1150)\",
                          ID[\"EPSG\",1154]],
                   MEMBER[\"World Geodetic System 1984 (G1674)\",
                          ID[\"EPSG\",1155]],
                   MEMBER[\"World Geodetic System 1984 (G1762)\",
                          ID[\"EPSG\",1156]],
                   MEMBER[\"World Geodetic System 1984 (G2139)\",
                          ID[\"EPSG\",1309]],
                   ELLIPSOID[\"WGS 84\",6378137,298.257223563,
                             LENGTHUNIT[\"metre\",1],
                             ID[\"EPSG\",7030]],
                   ENSEMBLEACCURACY[2.0],
                   ID[\"EPSG\",6326]],
          PRIMEM[\"Greenwich\",0,
                 ANGLEUNIT[\"degree\",0.0174532925199433],
                 ID[\"EPSG\",8901]],
          CS[ellipsoidal,2],
          AXIS[\"geodetic longitude (Lon)\",east,
               ORDER[1],
               ANGLEUNIT[\"degree\",0.0174532925199433,
                         ID[\"EPSG\",9122]]],
          AXIS[\"geodetic latitude (Lat)\",north,
               ORDER[2],
               ANGLEUNIT[\"degree\",0.0174532925199433,
                         ID[\"EPSG\",9122]]],
          USAGE[
            SCOPE[\"Horizontal component of 3D system.\"],
            AREA[\"World.\"],
            BBOX[-90,-180,90,180]],
          REMARK[\"Axis order reversed compared to EPSG:4326\"]]")

vect_subdiv <- load_vector_data(paste0("subdiv_", params$INN1))

vect_subdiv$ID <- seq.int(nrow(vect_subdiv))# add an id field
vect_subdiv$id <- formatC(vect_subdiv$ID, width = 2, format = "d", flag = "0") #format the id field

df_subdiv_area <- as.data.frame(expanse(vect_subdiv, unit="ha"))
df_subdiv_area <- cbind(df_subdiv_area, as.data.frame(vect_subdiv)$ID)
names(df_subdiv_area) <- c("ha","ID")
#names(df_subdiv_area) <- c("ha")
max_area <- max(df_subdiv_area)
 
 
vect_subdiv_extent <- ext(vect_subdiv) # get the extent
nudge_xval <-
  ((vect_subdiv_extent[2] - vect_subdiv_extent[1]) / (nrow(vect_subdiv) * 2.5))
nudge_yval <-
  ((vect_subdiv_extent[4] - vect_subdiv_extent[3]) / (nrow(vect_subdiv) * 2.5))

vect_subdiv_pt <- centroids(vect_subdiv)
expr <- paste0("vect_subdiv_pt$", params$SUBDIV1)
vect_subdiv_pt$subdiv_label <- paste(vect_subdiv_pt$id, "=", eval(parse(text=(expr))))
vect_subdiv_pt$subdiv_label <- factor(vect_subdiv_pt$subdiv_label)

g <- ggplot()
gsubdiv <- add_subdiv_plot(g)
gsubdiv

```
</div>

<div class="fold o">   
```{r i1_spatialdataload_vector_02, cache = FALSE, out.width="100%", include = TRUE, echo=FALSE}

vect_triangulation <- load_vector_data( paste0("triangulation_", params$INN1))

vect_triangulation$ID <- seq.int(nrow(vect_triangulation))# add an id field
vect_triangulation$id <- formatC(vect_triangulation$ID, width = 2, format = "d", flag = "0") #format the id field

vect_triangulation_extent <- ext(vect_triangulation) # get the extent
nudge_xvaltri <-
  ((vect_triangulation_extent[2] - vect_triangulation_extent[1]) /  (nrow(vect_triangulation) * 2.5))
#cat("nudge_xvaltri =", nudge_xvaltri)
nudge_yvaltri <-
  ((vect_triangulation_extent[4] - vect_triangulation_extent[3]) /  (nrow(vect_triangulation) * 2.5))
#cat("nudge_yvaltri =", nudge_yvaltri)


if (!is.na(params$TRIAD1)) {
  expr <- paste0("vect_triangulation$", params$TRIAD1)
  vect_triangulation$tri_label_ad <-
    paste(vect_triangulation$id, "=", eval(parse(text = (expr))))
  vect_triangulation$tri_label_ad <-
    factor(vect_triangulation$tri_label_ad)
  g_ad <- ggplot() +
      labs(title = paste("\nAdoption Triangulation Points - ", params$INN1))
  gtriangulation_ad <- add_triangulation_plot_no_labels_ad(g_ad)
  gtriangulation_ad <- add_subdiv_simple_plot(gtriangulation_ad)
  gtriangulation_ad
}

if (!is.na(params$TRIBA1)) {
  expr <- paste0("vect_triangulation$", params$TRIBA1)
  vect_triangulation$tri_label_ba <-
    paste(vect_triangulation$id, "=", eval(parse(text = (expr))))
  vect_triangulation$tri_label_ba <-
    factor(vect_triangulation$tri_label_ba)
  g_ba <- ggplot() +
      labs(title = paste("\nBiophysical Aptitude\nTriangulation Points - ", params$INN1))
  gtriangulation_ba <- add_triangulation_plot_no_labels_ba(g_ba)
  gtriangulation_ba <- add_subdiv_simple_plot(gtriangulation_ba)
  gtriangulation_ba
}

if (!is.na(params$TRISE1)) {
  expr <- paste0("vect_triangulation$", params$TRISE1)
  vect_triangulation$tri_label_se <-
    paste(vect_triangulation$id, "=", eval(parse(text = (expr))))
  vect_triangulation$tri_label_se <-
    factor(vect_triangulation$tri_label_se)
  g_se <- ggplot() +
      labs(title = paste("\nSocio-economic Feasibility\nTriangulation Points - ", params$INN1))
  gtriangulation_se <- add_triangulation_plot_no_labels_se(g_se)
  gtriangulation_se <- add_subdiv_simple_plot(gtriangulation_se)
  gtriangulation_se
}

```
</div>


## Raster Data

The raster spatial data are loaded first.
Only the mask need be in the working crs.

<div class="fold o">   
```{r i1_spatialdataload_raster_01, results='asis', warning=FALSE}

# set the working crs using WKT arguments

wkt_lam <-  paste0(
    "PROJCRS[\"unknown\",
    BASEGEOGCRS[\"unknown\",
        DATUM[\"World Geodetic System 1984\",
            ELLIPSOID[\"WGS 84\",6378137,298.257223563,
                LENGTHUNIT[\"metre\",1]],
            ID[\"EPSG\",6326]],
        PRIMEM[\"Greenwich\",0,
            ANGLEUNIT[\"degree\",0.0174532925199433],
            ID[\"EPSG\",8901]]],
    CONVERSION[\"unknown\",
        METHOD[\"Lambert Azimuthal Equal Area\",
            ID[\"EPSG\",9820]],
        PARAMETER[\"Latitude of natural origin\",",
vect_subdiv_extent[3],
    ",ANGLEUNIT[\"degree\",0.0174532925199433],
            ID[\"EPSG\",8801]],
        PARAMETER[\"Longitude of natural origin\",",
vect_subdiv_extent[1],
    ",ANGLEUNIT[\"degree\",0.0174532925199433],
            ID[\"EPSG\",8802]],
        PARAMETER[\"False easting\",1000000,
            LENGTHUNIT[\"metre\",1],
            ID[\"EPSG\",8806]],
        PARAMETER[\"False northing\",1000000,
            LENGTHUNIT[\"metre\",1],
            ID[\"EPSG\",8807]]],
    CS[Cartesian,2],
        AXIS[\"(E)\",east,
            ORDER[1],
            LENGTHUNIT[\"metre\",1,
                ID[\"EPSG\",9001]]],
        AXIS[\"(N)\",north,
            ORDER[2],
            LENGTHUNIT[\"metre\",1,
                ID[\"EPSG\",9001]]]]"
  )


# project the country boundary to LAM

vect_subdiv_proj <-  project(vect_subdiv, wkt_lam)
vect_subdiv_proj_extent <- terra::ext(vect_subdiv_proj)

# make a basic raster with dimensions with 100m resolution 
# and projected crs 

rast_subdiv_mask_proj_extent <- rast(crs = wkt_lam, extent = vect_subdiv_proj_extent, resolution = params$MASK)

# make the mask based on the country boundary

rast_subdiv_mask_proj <- terra::rasterize(
      vect_subdiv_proj,
      rast_subdiv_mask_proj_extent,
      field = 1,
      background = NA, touches = T
    ) 


# subset the priorities dataframe to keep only the records that have distinct raster data files

df_raster_data <- droplevels(distinct(df_priorities,
                                      data_file_prefix,
                                      .keep_all = T)) %>% drop_na(data_file_prefix)


# for each record in the df_raster_data data frame use the data file prefix and the raster or brick variable to load the raster data, the name of the raster is generated automatically from the data file name
# these rasters needn't have the same crs as the working crs but must have the crs in the metadata (e.g. geotiff format)

for (i in seq(from = 1,
              to = nrow(df_raster_data),
              by = 1)) {
  assign(
    paste0("rast_", df_raster_data[i, 12]),
    load_raster_data(
      as.character(df_raster_data[i, 12]),
      paste0("rast_", df_raster_data[i, 12])
    )
  )
  cat(paste0("\nrast_", df_raster_data[i, 12], " :"))
  print(get(paste0(
    "rast_", df_raster_data[i, 12]
  )))
}


```
</div>


# Common spatial resolution and extent

## Mask

Let's start with creating a 'mask', _i.e._, a raster map of the area of interest (1 = area to be modelled, NA = ignored). 

The properties of this map are given below:

<div class="fold o">  
```{r i1_mask01, cache = TRUE, cache.whatever=params$Agg, out.width="100%", warning=FALSE}

if (params$Agg == 1){rast_mask_proj <- rast_subdiv_mask_proj} else {
  rast_mask_proj <- aggregate(rast_subdiv_mask_proj, fact = params$Agg, na.rm=TRUE)}

g <- base_raster_plot(rast_mask_proj, "layer", 'red', 'blue', paste0("Aggregated mask - Resolution = ", res(rast_mask_proj), "m"))

gsubdivsimple <- add_subdiv_simple_plot(g)
gsubdivsimple

```
</div>

A factor is calculated to determine the area of each raster cell in hectares.

```{r i1_mask02, cache = FALSE, warning=FALSE }

Stat_factor_ha <- ((xres(rast_mask_proj)^2) / 10000) # factor used for statistical calculations divides the area of a raster cell (in m2) by 10000 to give the area of the cell in hectares 

cat(paste(Stat_factor_ha, "hectares in each cell"))

```

This mask designates the locations where predictions should be made, and an empty data frame (tibble) is created with records for all locations.


<div class="fold o">   
```{r i1_mask03, cache = TRUE, cache.whatever=params$Agg, warning=FALSE }

# only run the models for the areas in the mask

df_irm <- geom(terra::as.points(rast_mask_proj)) %>% as_tibble()

x <-  pull(df_irm, x)
y <-  pull(df_irm, y)
xy <- cbind(x, y)

if (params$INT == 1)
  shiny::setProgress(0.17, message = "Resampling data 1st Innovation")  # set progress to 17%
``` 
</div>


## Rough crop, Reproject, Aggregate and Resample

In this section the input spatial data are cropped to the extent of the sub-division boundary, projected if necessary and then aggregated and resampled if necessary.


```{r i1_agg_resample_01, message=FALSE, warning=FALSE, cache=TRUE, out.width="100%", results='hide'}

# do a rough crop of the thematic data for the country extent in the CRS of the thematic data

# for (i in seq(from = 1,
#               to = nrow(df_raster_data),
#               by = 1)) {
#   
#   temp_crs <- crs(get(paste0("rast_", df_raster_data[i, 12])))
#   assign("vect_subdiv_temp_crs", terra::project(vect_subdiv, temp_crs))
#   assign("vect_subdiv_temp_crs_extent", terra::ext(vect_subdiv_temp_crs))
#     
#   assign(
#     paste0("rast_", df_raster_data[i, 12], "_roughcrop"),
#     crop(get(paste0("rast_", df_raster_data[i, 12])),
#       vect_subdiv_temp_crs_extent)
#   )  
# }

# do a rough crop of the thematic data for the country extent in the CRS of the thematic data

for (i in seq(from = 1,
              to = nrow(df_raster_data),
              by = 1)) {
  
  temp_crs <- crs(get(paste0("rast_", df_raster_data[i, 12])))
  assign("vect_subdiv_temp_crs",
         terra::project(vect_subdiv, temp_crs))
  assign("vect_subdiv_temp_crs_extent",
         terra::ext(vect_subdiv_temp_crs))
  
  rast_roughcrop_filename <-
    paste0("spatial_data/input/rast_", df_raster_data[i, 12], "_roughcrop.tif")
  
  writeRaster(
    crop(get(paste0(
      "rast_", df_raster_data[i, 12]
    )),
    vect_subdiv_temp_crs_extent),
    here(rast_roughcrop_filename),
    overwrite = TRUE
  )
  
  assign(paste0("rast_", df_raster_data[i, 12], "_roughcrop"),
         rast(here(rast_roughcrop_filename)))
      

  gc()
}

 
```



<div class="fold o">   
```{r i1_agg_resample_02, cache = TRUE, out.width="100%", results='asis', warning=FALSE, message=FALSE}


# create an empty data frame for climatic variables
df_raster_data_clim <- df_raster_data[0,]

# create an empty data frame for soil variables with multiple horizons
df_raster_data_soil <- df_raster_data[0,]

# create an empty data frame for variables with single band data
df_raster_data_single <- df_raster_data[0,]


# reproject the raster data if necessary

for (i in seq(from = 1,
              to = nrow(df_raster_data),
              by = 1)) {

# compare the crs of the raster with the working crs
# when different project the raster  
  
  if ( paste(crs(get(paste0("rast_", df_raster_data[i, 12])))) %ni% paste(wkt_lam)) {  
  
  cat("different crs - ")  
  assign(
    paste0("rast_", df_raster_data[i, 12], "_prj"),
    raster_project(
      get(paste0("rast_", df_raster_data[i, 12], "_roughcrop")),
      #proj4_lam,
      as.character(df_raster_data[i, 15])
    )
  )  
  
  } else {

   cat("same crs - ") 
# when not different just create a new raster with the same prj suffix  
    assign(
    paste0("rast_", df_raster_data[i, 12], "_prj"),
    get(paste0("rast_", df_raster_data[i, 12], "_roughcrop"))
      )
  }

# calculate aggregate factor for each criterion for both dimensions of the raster (these are the same for a square cell shape)
  
#  cat(paste(df_raster_data[i, 10],"\n"))

  calc_agg_factor <-
    (res(rast_mask_proj) / res(get(paste0(
      "rast_", df_raster_data[i, 12], "_prj"
    ))))
  cat(paste("calculated aggregate factor = ", calc_agg_factor))
  cat("\n")

 if (calc_agg_factor[1] < 1) {
    calc_agg_factor[1] <- 1
    
    # this means that the mask has a higher resolution than the precipitation raster so aggregation is not necessary and the precipitation raster will stay the same resolution
    
#    cat(paste("revised calculated aggregate factor 1 = ", calc_agg_factor[1],"\n"))
  }
  
  
  
  if (calc_agg_factor[2] < 1) {
    calc_agg_factor[2] <- 1
    cat(paste("revised calculated aggregate factor 2 = ", calc_agg_factor[2]))
  }
  
  # for each record in the df_raster_data data frame use the data file prefix to recreate the raster name, and the aggregation and resample functions
#  cat(paste("aggregate and resample"))
  assign(
    paste0("rast_", df_raster_data[i, 12], "_rsmp"),
    agg_resample(
      get(paste0("rast_", df_raster_data[i, 12], "_prj")),
      calc_agg_factor,
      as.character(df_raster_data[i, 14]),
      as.character(df_raster_data[i, 15])
    )
  )
  
#  plot_raster <-
    terra::plot(
      get(paste0("rast_", df_raster_data[i, 12], "_rsmp")),
      main = paste0(
        as.character(df_raster_data[i, 11]),
        "\nagg ",
        as.character(df_raster_data[i, 14]),
        " rsmp ",
        as.character(df_raster_data[i, 15])
      ),
      breaks = 10
   )
  #print(plot_raster)
  
  dim_rast <<- dim(get(paste0("rast_", df_raster_data[i, 12], "_rsmp")))

  cat(paste("\nDim = ", dim_rast))
  cat("\n\n")
  
  if (dim_rast[[3]] > 1) {
    if (!is.na(df_raster_data[i, 16])) {
      df_raster_data_clim <-
        rbind(df_raster_data_clim, df_raster_data[i,])
    } else {
      df_raster_data_soil <-
        rbind(df_raster_data_soil, df_raster_data[i,])
    }
  } else {
    df_raster_data_single <-
      rbind(df_raster_data_single, df_raster_data[i,])
  }
  
  gc()    

#  plot_raster
#  terra::plot(rast_mask_proj, title = "") # this is needed (even if it is not actually plotted) to enable the plot of the raster
  
}


```
</div>

# Convert raw data to criteria values

Raster data with multiple bands will need to be processed before adding to the df_irm data frame.

If the criterion has a growth stage name then it is climatic and will need to undergo the climatic processing.

## Processing climatic data

```{r}

clim_raster_data_prefix <- df_raster_data_clim$data_file_prefix
df_priorities_clim <- df_priorities[0,]

for (i in clim_raster_data_prefix) { 
# if any of the clim raster data prefix values are in the priorities 
df_priorities_clim <-
        rbind(df_priorities_clim, subset(df_priorities, grepl(i, df_priorities$data_file_prefix)))
}


n_clim <- nrow(df_priorities_clim)
print(paste(n_clim, "Climatic criteria: "))

  for (i in 1:n_clim) {
  print(paste(df_priorities_clim[i, 4]))
  rast_clim_mask <- get(paste0("rast_",df_priorities_clim[i, 12], "_rsmp"))
  if (paste(df_priorities_clim[i, 25]) == "m") {
  rast_clim_mask_m <- rast_clim_mask
  names(rast_clim_mask_m) <- c(month.name)
  print("monthly data")
  } else {
  rast_clim_mask_d <- rast_clim_mask
  names(rast_clim_mask_d) <- c(1:36)
  print("dekadal data")}
}

```


<div class="fold o">   
```{r i1_requirements_phen_stages01, cache = TRUE, cache.whatever=params$Agg, out.width="100%", warning=FALSE}

## division by zero rainfall is infinitive, thus edited by Atkilt

if (exists('rast_clim_mask_m')) {
  values(rast_clim_mask_m)[values(rast_clim_mask_m) >= 0] = 0
  values(rast_clim_mask_m)[values(rast_clim_mask_m) < 0] = NA
}

if (exists('rast_clim_mask_d')) {
  values(rast_clim_mask_d)[values(rast_clim_mask_d) >= 0] = 0
  values(rast_clim_mask_d)[values(rast_clim_mask_d) < 0] = NA
}

```
</div>


```{r i1_growth_stages01, echo=FALSE, results='asis'}

cat("#### Growth Stages

Here we load the table of the growth stages.")

```


<div class="fold o"> 
```{r i1_growth_stages02, results='asis'}

# get the growth stages filename using the innovation parameter
growth_stages_filename <-
  as.character(paste("tab_data/input/growth_stages_", params$INN1, ".csv", sep = ""))

df_growth_stages <-  read.csv(here(growth_stages_filename))

df_growth_stages %>%
  kable(digits = 3, caption = "Growth Stage Lengths") %>% kable_styling("striped", full_width = T) %>% print

# create a new table just for where growth stage has requirements
df_growth_stages_req <-
  dplyr::filter(df_growth_stages, (prec_criteria == 1 |
                                  temp_criteria == 1))
df_growth_stages_req_prec <-
  dplyr::filter(df_growth_stages, prec_criteria == 1)
df_growth_stages_req_temp <-
  dplyr::filter(df_growth_stages, temp_criteria == 1)

```
</div>


<div class="fold o"> 
```{r i1_requirements_phen_stages_static01, cache = TRUE, cache.whatever=params$Agg, out.width="100%", warning=FALSE, eval=nonsos_crit_i1}

# see if one of the criteria is for the total growing period, if so then generate distribution

# this uses two functions from the irm package called .growth_period_long (for monthly data) and .growth_period_long_dekad (for dekadal data)

# both functions take three arguments: day_begin, and day_end in day numbers (obtained from the growth_stages_req table) and num_years which is calculated based on whether the growing season is spread across more than one calendar year


# for each of the growth stages for which there are requirements create a new raster brick
if (nonsos_crit_i1) {

cat("\n\n\n")
cat("#### Spatially Static Growing Seasons\n") # add headings
cat("\n\n\n")

  # get the number of variables in growth_stages (excluding sowing/planting date and total length)
  
  # create a list of the growth stages and determine the start and end days of each growth period


phen_tmp <- list()
for (i in seq_len(nrow(df_growth_stages) - 1)) {
  phen_tmp[[as.character(df_growth_stages[i + 1, 1])]] <-
    df_growth_stages[i + 1, 3]
}

phen_stages_beg <-
  df_growth_stages$day[1] + c(0, cumsum(phen_tmp)[c(-length(phen_tmp), -(length(phen_tmp)-1))], 0)
phen_stages_length <- unlist(phen_tmp)
phen_stages_end <- phen_stages_beg + phen_stages_length
names(phen_stages_beg) <- names(phen_tmp)
names(phen_stages_end) <- names(phen_tmp)

rbind(start = phen_stages_beg, end = phen_stages_end) %>%
  as.data.frame %>%
  kable(caption = "Growth Stage Days") %>% kable_styling("striped", full_width = T)  %>% print

num_years <- ceiling(phen_stages_end[["total"]] / 365)
cat(paste("Growth Stages span", num_years, "calendar years"))
}
```
</div>

<div class="fold o"> 
```{r i1_requirements_phen_stages_static02, cache = TRUE, cache.whatever=params$Agg, out.width="100%", warning=FALSE, eval=nonsos_crit_i1, results='asis'}

if (nonsos_crit_i1) {
  
# monthly distribution
if (exists('rast_clim_mask_m')) {
  for (i in seq_len(nrow(df_growth_stages_req))) {
    period_name <- as.character(df_growth_stages_req[i, 1])
    v_m <-
      .growth_period_long(phen_stages_beg[period_name], phen_stages_end[period_name], num_years)
    assign(paste0("rast_period_m_", df_growth_stages_req[i, 1]),
           rast_clim_mask_m %>%
             app(function(x) {
               ifelse(is.na(x), NA_real_, v_m)
             }))
    
#    plot_raster <-
      plot(
        get(paste0("rast_period_m_", df_growth_stages_req[i, 1])),
        maxnl = 12,
        breaks = c(0, 0.25, 0.5, 0.75, 1),
        axes = F,
        plg = list(cex = 1, title = paste0(df_growth_stages_req[i, 1]))
      )
#    print(plot_raster)
  }
}
# dekadal distribution
if (exists('rast_clim_mask_d')) {
  for (i in seq_len(nrow(df_growth_stages_req))) {
    period_name <- as.character(df_growth_stages_req[i, 1])
    v_d <-
      .growth_period_long_dekad(phen_stages_beg[period_name], phen_stages_end[period_name], num_years)
    assign(paste0("rast_period_d_", df_growth_stages_req[i, 1]),
           rast_clim_mask_d %>%
             app(function(x) {
               ifelse(is.na(x), NA_real_, v_d)
             }))
    
#    plot_raster <-
      plot(
        get(paste0("rast_period_d_", df_growth_stages_req[i, 1])),
        maxnl = 36,
        breaks = c(0, 0.25, 0.5, 0.75, 1),
        axes = F,
        plg = list(cex = 1, title = paste0(df_growth_stages_req[i, 1]))
      )

  }
}
}
``` 
</div>


```{r i1_requirements_sowing_dates_title, echo=FALSE, results='asis', eval=sos_crit_i1}

cat("#### Spatially Dynamic Growing Seasons")

```

```{r i1_requirements_sowing_dates_intro, echo=FALSE, results='asis',  eval=sos_crit_i1}

cat("For climatic criteria for specific growth stages which use monthly or dekadal data, and which have a spatially variable growth period the phenological stages need to be distributed over those periods and spatially.\n
\n
\n
The maps below give the distribution of each phenological stage over the months.\n
\n
I use the same function as Walvoort (here called growth_period_long_tbl and growth_period_long_dekad_tbl), and apply this on a cell-by-cell basis using the start and end days for each cell.\n
\n
When the function is applied to the tibble using 'apply' it produces a x *x* 12/36 matrix. I transpose this matrix, append it to the original tibble and create a temporary data frame. I save this as a csv, convert this to a spatvector object and create spatrasters for each month/dekad *x* growing period combination. I join the individual rasters in a SpatRaster brick for each growing period - to be used later.")

```


<div class="fold o">   
```{r i1_sowing_dates_sos_onsetdata_01, cache = TRUE, cache.whatever=params$Agg, out.width="100%", warning=FALSE, eval=sos_crit_i1}

if (sos_crit_i1) {
# get onset for area of interest
rast_filename_onset <-
  as.character(paste("spatial_data/input/rast_onset_",
                     params$INN1,
                     ".tif",
                     sep = ""))
assign(paste0("rast_onset"), rast(here(rast_filename_onset)))
names(rast_onset) <- c("onset")
rast_onset

g <- base_raster_plot(rast_onset, "onset", 'red', 'blue', "Season onset day number (rast_onset)" )

gsubdivsimple <- add_subdiv_simple_plot(g)
gsubdivsimple
}
```
</div>


<div class="fold o">   
```{r i1_sowing_dates_sos_onsetdata_02, cache = TRUE, cache.whatever=params$Agg, out.width="100%", warning=FALSE, eval=sos_crit_i1}

if (sos_crit_i1) {
# project onset
rast_onset_proj <- project(rast_onset, rast_mask_proj, method = "near")
rast_onset_proj

g <- base_raster_plot(rast_onset_proj, "onset", 'red', 'blue', "Season onset day number (rast_onset_proj)" )

gsubdivsimple <- add_subdiv_simple_plot(g)
gsubdivsimple
}
```
</div>


<div class="fold o">   
```{r i1_sowing_dates_sos_onsetdata_03, cache = TRUE, cache.whatever=params$Agg,  out.width="100%", warning=FALSE, eval=sos_crit_i1}

if (sos_crit_i1) {
# do a rough crop to boundaries
rast_onset_crop <- crop(rast_onset_proj, rast_mask_proj)
rast_onset_crop

g <- base_raster_plot(rast_onset_crop, "onset", 'red', 'blue', "Season onset day number (rast_onset_crop)" )

gsubdivsimple <- add_subdiv_simple_plot(g)
gsubdivsimple
}

```
</div>


<div class="fold o">   
```{r i1_sowing_dates_sos_onsetdata_04, cache = TRUE, cache.whatever=params$Agg, out.width="100%", warning=FALSE, eval=sos_crit_i1}
if (sos_crit_i1) {
rast_onset_crop_rsmp <- resample(rast_onset_crop, rast_mask_proj,  method="near")
rast_onset_crop_rsmp


g <- base_raster_plot(rast_onset_crop_rsmp, "onset", 'red', 'blue', "Season onset day number (rast_onset_crop_rsmp)" )

gsubdivsimple <- add_subdiv_simple_plot(g)
gsubdivsimple
}
```
</div>

<div class="fold o">   
```{r i1_sowing_dates_sos_onsetdata_05, cache = TRUE, cache.whatever=params$Agg, out.width="100%", warning=FALSE, eval=sos_crit_i1}

if (sos_crit_i1) {
# convert to df
df_onset <- as.data.frame(rast_onset_crop_rsmp, xy=TRUE, cells=TRUE, na.rm=NA)
df_onset <- mutate(df_onset, onset = as.integer(onset))
}
```
</div>

<div class="fold o">   
```{r i1_sowing_dates_sos_transpose, cache = TRUE, cache.whatever=params$Agg,  out.width="100%", warning=FALSE,  eval=sos_crit_i1}

if (sos_crit_i1) {
df_growth_stages_lengths <- df_growth_stages[-1, ]
#df_growth_stages_lengths

df_growth_stages_lengths1 <- t(select(df_growth_stages_lengths, name, length)) %>% data.frame()
#df_growth_stages_lengths1

df_growth_stages_lengths2 <- setNames(df_growth_stages_lengths1, df_growth_stages_lengths[,1])
#df_growth_stages_lengths2

df_growth_stages_lengths3 <- df_growth_stages_lengths2[-1, ] 
#df_growth_stages_lengths3

df_growth_stages_lengths3[] <- lapply(df_growth_stages_lengths3, as.integer)
df_growth_stages_lengths3 %>%
  kable(caption = "Growth Stage Days") %>% kable_styling("striped", full_width = T)  #%>% print
}
```
</div>

<div class="fold o">   
```{r i1_sowing_dates_sos_onsetdata_06, cache = TRUE, cache.whatever=params$Agg,  out.width="100%", warning=FALSE,  eval=sos_crit_i1}

if (sos_crit_i1) {
# add the growth stage lengths to the df
for (i in seq_len(nrow(df_growth_stages_lengths))) {
  period_name <- as.character(df_growth_stages_lengths[i, 1])
#  cat(paste(period_name))
#  cat(eval(parse(text = paste0("df_growth_stages_lengths3$", period_name))))
  df_onset <-  mutate(df_onset, !!as.character(paste0(period_name,"_l")) :=  eval(parse(text = paste0("df_growth_stages_lengths3$", period_name))), .keep = c("all"))
} 


# add the start day for the first growth stage (which is the onset)

first_period_name <- as.character(df_growth_stages_lengths[1, 1])
#cat(paste(first_period_name))
df_onset <-
  mutate(df_onset,!!as.character(paste0(first_period_name, "_s")) :=  eval(parse(text = paste0(
    "df_onset$onset"
  ))),
  .keep = c("all"))

# add the start days for each of the growth stages (excluding the first which is the onset)

for (i in seq_len(nrow(df_growth_stages_lengths)- 2) ) {
  
#  cat(paste(i))
      
  previous_period_name <- as.character(df_growth_stages_lengths[i, 1])
#  cat(paste("Prev = ", previous_period_name))
#  cat("\n")
  period_name <- as.character(df_growth_stages_lengths[i + 1, 1])
#  cat(paste("Current = ", period_name))
#  cat("\n")
#  cat(paste0("df_growth_stages_lengths3$", period_name))
#  cat(paste(parse(text =paste0("df_onset$", previous_period_name,"_s"))))
#  cat("\n")
#  cat(paste(parse(text =paste0("df_onset$", previous_period_name,"_l"))))
#  cat("\n\n")
 
eval_expr_1 <- eval(parse(text =paste0("df_onset$", previous_period_name, "_s + df_onset$", previous_period_name,"_l")))

  df_onset <-
    mutate(df_onset, !!as.character(paste0(period_name, "_s")) :=  eval_expr_1,
           .keep = c("all"))

}

# add the end days for each of the growth stages

for (i in seq_len(nrow(df_growth_stages_lengths) - 1) ) {
  
#  cat(paste(i))
      
#  previous_period_name <- as.character(df_growth_stages_lengths[i, 1])
#  cat(paste("Prev = ", previous_period_name))
#  cat("\n")
  period_name <- as.character(df_growth_stages_lengths[i, 1])
#  cat(paste("Current = ", period_name))
#  cat("\n")
#  cat(paste0("df_growth_stages_lengths3$", period_name))
#  cat(paste(parse(text =paste0("df_onset$", period_name,"_s"))))
#  cat("\n")
#  cat(paste(parse(text =paste0("df_onset$", period_name,"_l"))))
#  cat("\n\n")
 
eval_expr_2 <- eval(parse(text =paste0("df_onset$", period_name, "_s + df_onset$", period_name,"_l - 1")))

  df_onset <-
    mutate(df_onset, !!as.character(paste0(period_name, "_e")) :=  eval_expr_2,
           .keep = c("all"))

}  
  
onset_max <- max(select(df_onset, -cell, -x, -y)) # gets the maximum value of the julian day numbers
num_years <- max(ceiling(onset_max / 365))

cat(paste("Growth Stages span", num_years, "calendar years"))
}
```
</div>

<div class="fold o">
```{r i1_sowing_dates_sos_maps_m, cache = TRUE, cache.whatever=params$Agg,  out.width="100%", warning=FALSE, eval=sos_crit_i1}

# to reduce unnecessary processing follow these steps
# for each growth stage:

# (1) does the monthly and/or dekad raster mask exist on file?
#   YES - (i) load raster file to env
#         (ii) plot raster file
#         (iii) move to next growth stage or next chunk
#   NO -  (i) go to (2)

# (2) does the monthly and/or dekad raster mask csv exist on file?
#   YES - (i) load csv file to env as vect
#         (ii) rasterize vect
#         (iii) write raster to file
#         (iv) go to (1)
#   NO -  (i) go to (3)

# (3) does the monthly and/or dekad raster mask df exist in the env?
#   YES - (i) write df to file as csv
#         (ii) go to (2)
#   NO -  (i) go to (4)

# (4) does the monthly and/or dekad raster mask matrix exist in the env?
#   YES - (i) join the matrix to the onset df
#         (ii) write df to file as csv
#         (iii) go to (3)
#   NO -  (i) create the matrix using the growth_period_long functions
#         (ii) join the matrix to the onset df
#         (iii) go to (4)

if (sos_crit_i1) {
if (exists('rast_clim_mask_m')) {
  cat(paste("\n1 Monthly data exist"))
    
  # set static vectors of days and months
  days <- 1:365
  day_months <- days %>% as.character %>% as.Date("%j") %>% 
    format("%m") %>% as.integer
  months <- rep.int(day_months, num_years)
  
  
  for (i in seq_len(nrow(df_growth_stages_lengths))) {
    period_name <- as.character(df_growth_stages_lengths[i, 1])
    cat(paste("\nCurrent growth stage = ", period_name))
    
    rast_filename_m <-
      as.character(paste0(
        "spatial_data/output/rast_",
        period_name,
        "_m_",
        params$INN1, "_", params$MASK,
        ".tif"
      ))
    
    if (!file.exists(here(rast_filename_m))) {
      cat(paste("\n2 No spatraster"))
      
      if (!exists(paste0("vect_", period_name, "_m"))) {
        cat(paste("\n3 No spatvector"))
        
        csv_filename_m <-
          as.character(
            paste(
              "tab_data/output/df_onset_",
              period_name,
              "_m_",
              params$INN1, "_", params$MASK,
              ".csv",
              sep = ""
            )
          )
        
        if (!file.exists(here(csv_filename_m))) {
          cat(paste("\n4 No csv data"))
          
          if (!exists(paste0("df_onset_", period_name, "_m"))) {
            cat(paste("\n5 No df"))
            
            if (!exists(paste0(period_name, "_matrix_days_m"))) {
              cat(paste("\n6 No matrix"))
              
              if (period_name == "total") {
                expr_3_m <- parse(
                  text = paste0(
                    "t(apply(df_onset, 1, .growth_period_long_tbl_short, day_begin = \"onset\", day_end = \"",
                    df_growth_stages_lengths[nrow(df_growth_stages_lengths) - 1, 1],
                    "_e\", num_years = num_years))"
                  )
                )
              } else {
                expr_3_m <- parse(
                  text = paste0(
                    "t(apply(df_onset, 1, .growth_period_long_tbl_short, day_begin = \"",
                    period_name,
                    "_s\",
        day_end = \"",
        period_name,
        "_e\", num_years = num_years))"
                  )
                )
              }
              
              assign(paste0(period_name, "_matrix_days_m"),
                     eval(expr_3_m))
                            
                            expr_3_m2 <- parse(
                  text = paste0(period_name, "_matrix_days_m * 1000"))
              
              assign(paste0(period_name, "_matrix_days_m"), eval(expr_3_m2))
              
              eval(parse(text = paste0(
                "mode(", period_name, "_matrix_days_m) <- \"integer\""
              )))
              
              cat(paste("\n-6"))
            }
            
            
            assign(paste0("df_onset_", period_name, "_m"),
                   data.frame(df_onset, get(
                     paste0(period_name, "_matrix_days_m")
                   )))
            
            cat(paste("\n-5"))
          }
          
          rm(list = paste0(period_name, "_matrix_days_m")) # remove matrix when df created
          
          write.csv(get(paste0("df_onset_", period_name, "_m")),
                    here(csv_filename_m))
          
          cat(paste("\n-4"))
        }
        rm(list = paste0("df_onset_", period_name, "_m")) # remove df when csv created
        assign(paste0("vect_", period_name, "_m"),
               vect(
                 read_csv(here(csv_filename_m), show_col_types = FALSE),
                 geom = c("x", "y"),
                 crs = wkt_lam
               ))
        cat(paste("\n-3"))
      }
      
      
      assign(paste0("list_rast_", period_name, "_m"),
             list())
      
      #create an empty raster
      assign(paste0("rast_", period_name, "_m"), rast())
      
      for (j in 1:12) {
        assign(
          paste0("rast_", period_name, "_m_", j),
          rasterize(get(
            paste0("vect_", period_name, "_m")
          ), rast_clim_mask_m, field = paste0("X", j))
        )
        
        assign(paste0("list_rast_", period_name, "_m"),
               append(get(
                 paste0("list_rast_", period_name, "_m")
               ), paste0("rast_", period_name, "_m_", j)))
        expr_5_m <-
          parse(text = paste0(
            "add(rast_",
            period_name,
            "_m) <- (rast_",
            period_name,
            "_m_",
            j,
            ")"
          ))
        
        eval(expr_5_m)
        rm(list = paste0("rast_", period_name, "_m_", j)) # remove month rast when added to brick
      }
      
      rm(list = paste0("vect_", period_name, "_m")) # remove vect when raster created
      writeRaster(get(paste0("rast_", period_name, "_m")), here(rast_filename_m), overwrite = TRUE)
      cat(paste("\n-2"))
    }
    
    assign(paste0("rast_", period_name, "_m"), rast(here(rast_filename_m)))
    cat(paste0("\n", rast_filename_m))
    
    expr_6_m <-
      parse(
        text = paste0(
          "names(rast_",
          period_name,
          "_m) <- c(\"January\", \"February\", \"March\", \"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\")"
        )
      )
    
    eval(expr_6_m)
    
#    plot(
#      get(paste0("rast_", period_name, "_m")),
#      maxnl = 12,
#      breaks = c(0, 0.25, 0.5, 0.75, 1),
#      axes = F,
#      plg = list(cex = 1, title = paste0(period_name))
#    )
    
  }
  cat(paste("\n-1"))
}
}
```
</div>

<div class="fold o">
```{r i1_sowing_dates_sos_maps_d, cache = TRUE, cache.whatever=params$Agg,  out.width="100%", warning=FALSE, eval=sos_crit_i1}

# to reduce unnecessary processing follow these steps
# for each growth stage:

# (1) does the monthly and/or dekad raster mask exist on file?
#   YES - (i) load raster file to env
#         (ii) plot raster file
#         (iii) move to next growth stage or next chunk
#   NO -  (i) go to (2)

# (2) does the monthly and/or dekad raster mask csv exist on file?
#   YES - (i) load csv file to env as vect
#         (ii) rasterize vect
#         (iii) write raster to file
#         (iv) go to (1)
#   NO -  (i) go to (3)

# (3) does the monthly and/or dekad raster mask df exist in the env?
#   YES - (i) write df to file as csv
#         (ii) go to (2)
#   NO -  (i) go to (4)

# (4) does the monthly and/or dekad raster mask matrix exist in the env?
#   YES - (i) join the matrix to the onset df
#         (ii) write df to file as csv
#         (iii) go to (3)
#   NO -  (i) create the matrix using the growth_period_long functions
#         (ii) join the matrix to the onset df
#         (iii) go to (4)

if (sos_crit_i1) {
if (exists('rast_clim_mask_d')) {
  cat(paste("\n1 Dekad data exist"))
  
  # set static vectors of days and dekads
  days <- 1:365
  day_dekads <- days %>% as.character %>% as.Date("%j") %>%
    dekad(type = "year") %>% as.integer
  dekads <- rep.int(day_dekads, num_years)
  
  
  for (i in seq_len(nrow(df_growth_stages_lengths))) {
    period_name <- as.character(df_growth_stages_lengths[i, 1])
    cat(paste("\nCurrent growth stage = ", period_name))
    
    
    rast_filename_d <-
      as.character(paste0(
        "spatial_data/output/rast_",
        period_name,
        "_d_",
        params$INN1, "_", params$MASK, 
        ".tif"
      ))
    
    if (!file.exists(here(rast_filename_d))) {
      cat(paste("\n2 No spatraster"))
      
      if (!exists(paste0("vect_", period_name, "_d"))) {
        cat(paste("\n3 No spatvector"))
        
        csv_filename_d <-
          as.character(
            paste(
              "tab_data/output/df_onset_",
              period_name,
              "_d_",
              params$INN1, "_", params$MASK,
              ".csv",
              sep = ""
            )
          )
        
        if (!file.exists(here(csv_filename_d))) {
          cat(paste("\n4 No csv data"))
          
          if (!exists(paste0("df_onset_", period_name, "_d"))) {
            cat(paste("\n5 No df"))
            
            if (!exists(paste0(period_name, "_matrix_days_d"))) {
              cat(paste("\n6 No matrix"))
              
              if (period_name == "total") {
                expr_3_d <- parse(
                  text = paste0(
                    "t(apply(df_onset, 1, .growth_period_long_dekad_tbl_short, day_begin = \"onset\", day_end = \"",
                    df_growth_stages_lengths[nrow(df_growth_stages_lengths) - 1, 1],
                    "_e\", num_years = num_years))"
                  )
                )
              } else {
                expr_3_d <- parse(
                  text = paste0(
                    "t(apply(df_onset, 1, .growth_period_long_dekad_tbl_short, day_begin = \"",
                    period_name,
                    "_s\",
        day_end = \"",
        period_name,
        "_e\", num_years = num_years))"
                  )
                )
              }
              
              assign(paste0(period_name, "_matrix_days_d"),
                     eval(expr_3_d))
              expr_3_d2 <- parse(
                  text = paste0(period_name, "_matrix_days_d * 1000"))
              
              assign(paste0(period_name, "_matrix_days_d"), eval(expr_3_d2))
              
              eval(parse(text = paste0(
                "mode(", period_name, "_matrix_days_d) <- \"integer\""
              )))
              
              cat(paste("\n-6"))
            }
            
            assign(paste0("df_onset_", period_name, "_d"),
                   data.frame(df_onset, get(
                     paste0(period_name, "_matrix_days_d")
                   )))
            
            cat(paste("\n-5"))
          }
          rm(list = paste0(period_name, "_matrix_days_d")) # remove matrix when df created
          write.csv(get(paste0("df_onset_", period_name, "_d")),
                    here(csv_filename_d))
          
          cat(paste("\n-4"))
        }
        rm(list = paste0("df_onset_", period_name, "_d")) # remove df when csv created
        assign(paste0("vect_", period_name, "_d"),
               vect(
                 read_csv(here(csv_filename_d), show_col_types = FALSE),
                 geom = c("x", "y"),
                 crs = wkt_lam
               ))
        cat(paste("\n-3"))
      }
      assign(paste0("list_rast_", period_name, "_d"),
             list())
      
      #create an empty raster
      assign(paste0("rast_", period_name, "_d"), rast())
      
      for (j in 1:36) {
        assign(
          paste0("rast_", period_name, "_d_", j),
          rasterize(get(
            paste0("vect_", period_name, "_d")
          ), rast_clim_mask_d, field = paste0("X", j))
        )
        
        assign(paste0("list_rast_", period_name, "_d"),
               append(get(
                 paste0("list_rast_", period_name, "_d")
               ), paste0("rast_", period_name, "_d_", j)))
        expr_5_d <-
          parse(text = paste0(
            "add(rast_",
            period_name,
            "_d) <- (rast_",
            period_name,
            "_d_",
            j,
            ")"
          ))
        
        eval(expr_5_d)
        rm(list = paste0("rast_", period_name, "_d_", j)) # remove dekad rast when added to brick
        
      }
      
      rm(list = paste0("vect_", period_name, "_d")) # remove vect when raster created
      writeRaster(get(paste0("rast_", period_name, "_d")), here(rast_filename_d), overwrite = TRUE)
      cat(paste("\n-2"))
    }
    
    assign(paste0("rast_", period_name, "_d"), rast(here(rast_filename_d)))
    cat(paste0("\n", rast_filename_d))
    
    expr_6_d <-
      parse(
        text = paste0(
          "names(rast_",
          period_name,
          "_d) <- c(\"Ja1\", \"Ja2\", \"Ja3\", \"Fe1\", \"Fe2\", \"Fe3\",\"Mr1\", \"Mr2\", \"Mr3\",\"Ap1\", \"Ap2\", \"Ap3\",\"My1\", \"My2\", \"My3\",\"Jn1\", \"Jn2\", \"Jn3\",\"Jl1\",\"Jl2\", \"Jl3\",\"Ag1\",\"Ag2\", \"Ag3\",\"Sp1\",\"Sp2\", \"Sp3\",\"Oc1\",\"Oc2\", \"Oc3\",\"No1\",\"No2\", \"No3\",\"De1\",\"De2\", \"De3\")"
        )
      )
    
    eval(expr_6_d)
    
#    plot(
#      get(paste0("rast_", period_name, "_d")),
#      maxnl = 36,
#      breaks = c(0, 0.25, 0.5, 0.75, 1),
#      axes = F,
#      plg = list(cex = 1, title = paste0(period_name))
#    )
    
  }
  cat(paste("\n-1"))
}
}
```
</div>

<div class="fold o">   
```{r i1_requirements_phen_stages01_sos_m, cache = TRUE, cache.whatever=params$Agg,  out.width="100%", warning=FALSE, eval=sos_crit_i1}

##-- monthly distribution --
if (sos_crit_i1) {
if (exists('rast_clim_mask_m')) {
  for (i in seq_len(nrow(df_growth_stages_req))) {
    period_name <- as.character(df_growth_stages_req[i, 1])
    cat("period_name = ", period_name, "\n")
    
    
    # load growth period rasters
    rast_filename_m <-
      as.character(paste0(
        "spatial_data/output/rast_",
        period_name,
        "_m_",
        params$INN1, "_", params$MASK,
        ".tif"
      ))
    
    assign(paste0("rast_period_m_", period_name, "_original"),
           rast(here(rast_filename_m))/1000) # divide by 1000 because the values were multiplied by 1000 when creating the matrix
    
    # reproject growth period rasters
    
    assign(
      paste0("rast_period_m_", period_name, "_prj"),
      terra::project(get(
        paste0("rast_period_m_", period_name, "_original")
      ),   rast_mask_proj, "near")
    )
    
    # aggregate if necessary
    
    #calc_agg_factor_m <-
    #    (res(rast_mask_proj) / res(rast_period_m_total_prj))
    #  cat(paste("calculated aggregate factor m = ", calc_agg_factor_m))
    
    calc_agg_factor_m <-
      (res(rast_mask_proj) / res(get(
        paste0("rast_period_m_", period_name, "_prj")
      )))
    
    cat(paste("calculated aggregate factor m = ", calc_agg_factor_m))
    
    
    if (calc_agg_factor_m[1] < 1) {
      calc_agg_factor_m[1] <- 1
      
      # this means that the mask has a higher resolution than the precipitation raster so aggregation is not necessary and the precipitation raster will stay the same resolution
      
      cat(paste(
        "revised calculated aggregate factor m1 = ",
        calc_agg_factor_m[1]
      ))
    }
    cat("\n")
    
    if (calc_agg_factor_m[2] < 1) {
      calc_agg_factor_m[2] <- 1
      cat(paste(
        "revised calculated aggregate factor m2 = ",
        calc_agg_factor_m[2]
      ))
    }
    
    # resample
    
    cat(paste("aggregate and resample"))
    
    #    rast_period_m_total <-
    #    agg_resample(
    #      rast_period_m_total_prj,
    #      calc_agg_factor_m, "modal", "near")
    
    assign(
      paste0("rast_period_m_", period_name),
      agg_resample(get(
        paste0("rast_period_m_", period_name, "_prj")
      ),
      calc_agg_factor_m, "modal", "near")
    )
    
    # plot
    
    expr_7_m <-
      parse(
        text = paste0(
          "names(rast_period_m_",
          period_name,
          ") <- c(\"January\", \"February\", \"March\", \"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\")"
        )
      )
    
    eval(expr_7_m)
    plot(
      get(paste0("rast_period_m_", period_name)),
      maxnl = 12,
      breaks = c(0, 0.25, 0.5, 0.75, 1),
      axes = F,
      plg = list(cex = 1, title = paste0(period_name))
    )
    
  }
}
}
```  
</div>    
 
<div class="fold o">   
```{r i1_requirements_phen_stages01_sos_d, cache = TRUE, cache.whatever=params$Agg,  out.width="100%", warning=FALSE, eval=sos_crit_i1}

# dekadal growth stages have been pre-modelled for the spatial onset of season

# for each of the growth stages for which there are requirements create a new raster brick

##-- dekadal distribution --

if (sos_crit_i1) {
if (exists('rast_clim_mask_d')) {
  for (i in seq_len(nrow(df_growth_stages_req))) {
    period_name <- as.character(df_growth_stages_req[i, 1])
    cat("period_name = ", period_name, "\n")
    
    
    # load growth period rasters
    rast_filename_d <-
      as.character(paste0(
        "spatial_data/output/rast_",
        period_name,
        "_d_",
        params$INN1, "_", params$MASK,
        ".tif"
      ))
    
    assign(paste0("rast_period_d_", period_name, "_original"),
           rast(here(rast_filename_d))/1000) # divide by 1000 because the values were multiplied by 1000 when creating the matrix
    
    # reproject growth period rasters
    
    assign(
      paste0("rast_period_d_", period_name, "_prj"),
      terra::project(get(
        paste0("rast_period_d_", period_name, "_original")
      ),   rast_mask_proj, "near")
    )
    
    # aggregate if necessary
    
    #calc_agg_factor_d <-
    #    (res(rast_mask_proj) / res(rast_period_d_total_prj))
    #  cat(paste("calculated aggregate factor m = ", calc_agg_factor_d))
    
    calc_agg_factor_d <-
      (res(rast_mask_proj) / res(get(
        paste0("rast_period_d_", period_name, "_prj")
      )))
    
    cat(paste("calculated aggregate factor d = ", calc_agg_factor_d))
    
    
    if (calc_agg_factor_d[1] < 1) {
      calc_agg_factor_d[1] <- 1
      
      # this means that the mask has a higher resolution than the precipitation raster so aggregation is not necessary and the precipitation raster will stay the same resolution
      
      cat(paste(
        "revised calculated aggregate factor d1 = ",
        calc_agg_factor_d[1]
      ))
    }
    cat("\n")
    
    if (calc_agg_factor_d[2] < 1) {
      calc_agg_factor_d[2] <- 1
      cat(paste(
        "revised calculated aggregate factor d2 = ",
        calc_agg_factor_d[2]
      ))
    }
    
    # resample
    
    cat(paste("aggregate and resample"))
    
    #    rast_period_d_total <-
    #    agg_resample(
    #      rast_period_d_total_prj,
    #      calc_agg_factor_d, "modal", "near")
    
    assign(
      paste0("rast_period_d_", period_name),
      agg_resample(get(
        paste0("rast_period_d_", period_name, "_prj")
      ),
      calc_agg_factor_d, "modal", "near")
    )
    
    # plot
    
    expr_7_d <-
      parse(
        text = paste0(
          "names(rast_period_d_",
          period_name,
          ") <- c(\"Ja1\", \"Ja2\", \"Ja3\", \"Fe1\", \"Fe2\", \"Fe3\",\"Mr1\", \"Mr2\", \"Mr3\",\"Ap1\", \"Ap2\", \"Ap3\",\"My1\", \"My2\", \"My3\",\"Jn1\", \"Jn2\", \"Jn3\",\"Jl1\",\"Jl2\", \"Jl3\",\"Ag1\",\"Ag2\", \"Ag3\",\"Sp1\",\"Sp2\", \"Sp3\",\"Oc1\",\"Oc2\", \"Oc3\",\"No1\",\"No2\", \"No3\",\"De1\",\"De2\", \"De3\")"
        )
      )
    
    eval(expr_7_d)
    plot(
      get(paste0("rast_period_d_", period_name)),
      maxnl = 36,
      breaks = c(0, 0.25, 0.5, 0.75, 1),
      axes = F,
      plg = list(cex = 1, title = paste0(period_name))
    )
    
  }
}
}
```     
</div> 

### Processing precipitation data

<div class="fold o">   
```{r i1_requirements_prec02, cache = TRUE, cache.whatever=params$Agg,  out.width="100%", fig.show="hold", warning=FALSE}

df_priorities_clim_prec_m <-
  dplyr::filter(df_priorities_clim, prec_temp == "p" &
                  temp_resolution == "m") # filter precipitation criteria

for (i in seq_len(nrow(df_growth_stages_req_prec))) {
  period_name <- as.character(df_growth_stages_req_prec[i, 1])
  #      print(period_name)
  
  for (j in seq_len(nrow(df_priorities_clim_prec_m))) {
    if (sum(df_priorities_clim_prec_m[j, 'phen_stage'] == period_name, na.rm = TRUE) == 1) {
      print(paste0("period_name = ", as.character(period_name)))
      # crit_rownum <-
      #   which(df_priorities_clim_prec_m$phen_stage == period_name)
      assign(
        paste0(
          "rast_",
          df_priorities_clim_prec_m[j, 12],
          "_rsmp_",
          df_growth_stages_req_prec[i, 1]
        ),
        sum(get(
          paste0("rast_", df_priorities_clim_prec_m[j, 12], "_rsmp")
        ) * get(
          paste0("rast_period_m_", df_growth_stages_req_prec[i, 1])
        ))
      )
      print(
        paste0(
          "rast_",
          df_priorities_clim_prec_m[j, 12],
          "_rsmp_",
          df_growth_stages_req_prec[i, 1]
        )
      )
      #        plot_raster <-
      plot(get(
        paste0(
          "rast_",
          df_priorities_clim_prec_m[j, 12],
          "_rsmp_",
          df_growth_stages_req_prec[i, 1]
        )
      ),
      main = paste0(
        "rast_period_m_",
        as.character(df_growth_stages_req_prec[i, 1])
      ))
      #        print(plot_raster)
      
      
      new_col <-
        get(
          paste0(
            "rast_",
            df_priorities_clim_prec_m[j, 12],
            "_rsmp_",
            df_growth_stages_req_prec[i , 1]
          )
        ) %>% terra::extract(xy) # extract the raster values using xy points
      
      new_col <- new_col[[1]]
      
      df_irm <-
        dplyr::select(df_irm,-any_of(c(as.character(
          paste0(df_priorities_clim_prec_m[j, 3])
        )))) # remove column if name already exists
      
      df_irm <-
        mutate(df_irm,!!as.character(paste0(df_priorities_clim_prec_m[j, 3])) := new_col,
               .keep = c("all"))   # add the raster values to the df_irm tibble, this needs to be dynamic so uses the !! and := operators
      
      
    } else {
      #    print(sum(df_priorities_clim_prec_m[, 'phen_stage'] == period_name, na.rm = TRUE))
    }
  }
}

df_priorities_clim_prec_d <-
  dplyr::filter(df_priorities_clim, prec_temp == "p" &
                  temp_resolution == "d") # filter precipitation criteria

for (i in seq_len(nrow(df_growth_stages_req_prec))) {
  period_name <- as.character(df_growth_stages_req_prec[i, 1])
  # print(period_name)
  for (j in seq_len(nrow(df_priorities_clim_prec_d))) {
    if (sum(df_priorities_clim_prec_d[i, 'phen_stage'] == period_name, na.rm = TRUE) == 1) {
      print(paste0("period_name = ", as.character(period_name)))
      # crit_rownum <-
      #   which(df_priorities_clim_prec_d$phen_stage == period_name)
      assign(
        paste0(
          "rast_",
          df_priorities_clim_prec_d[j, 12],
          "_rsmp_",
          df_growth_stages_req_prec[i, 1]
        ),
        sum(get(
          paste0("rast_", df_priorities_clim_prec_d[j, 12], "_rsmp")
        ) * get(
          paste0("rast_period_d_", df_growth_stages_req_prec[i, 1])
        ))
      )
      print(
        paste0(
          "rast_",
          df_priorities_clim_prec_d[j, 12],
          "_rsmp_",
          df_growth_stages_req_prec[i, 1]
        )
      )
      #        plot_raster <-
      plot(get(
        paste0(
          "rast_",
          df_priorities_clim_prec_d[j, 12],
          "_rsmp_",
          df_growth_stages_req_prec[i, 1]
        )
      ),
      main = paste0(
        "rast_period_d_",
        as.character(df_growth_stages_req_prec[i, 1])
      ))
      #        print(plot_raster)
      
      
      new_col <-
        get(
          paste0(
            "rast_",
            df_priorities_clim_prec_d[j, 12],
            "_rsmp_",
            df_growth_stages_req_prec[i , 1]
          )
        ) %>% terra::extract(xy) # extract the raster values using xy points
      
      new_col <- new_col[[1]]
      
      df_irm <-
        dplyr::select(df_irm, -any_of(c(as.character(
          paste0(df_priorities_clim_prec_d[j, 3])
        )))) # remove column if name already exists
      
      df_irm <-
        mutate(df_irm,
               !!as.character(paste0(df_priorities_clim_prec_d[j, 3])) := new_col,
               .keep = c("all"))   # add the raster values to the df_irm tibble, this needs to be dynamic so uses the !! and := operators
      
      
    } else {
      #   print(sum(df_priorities_clim_prec_d[, 'phen_stage'] == period_name, na.rm = TRUE))
    }
  }
}

df_priorities_clim_prec <-
  rbind(df_priorities_clim_prec_m, df_priorities_clim_prec_d)

``` 
</div>

### Processing temperature data

<div class="fold o">   
```{r i1_requirements_temp02, cache = TRUE, cache.whatever=params$Agg,  out.width="100%", fig.show="hold", warning=FALSE}

# A Farrow 01/06/2023 the following assumes that there is only one temperature criterion per growth stage
# In fact there may be multiple so a different way of looping through the criteria is needed


# for monthly temperature data

# logic
# for each temperature criterion i
# for each phen stage for which there is a criterion j
# do the appropriate calculation


df_priorities_clim_temp_m <-
  dplyr::filter(df_priorities_clim, prec_temp == "t" &
                  temp_resolution == "m") # filter temperature criteria

if (nrow(df_priorities_clim_temp_m) > 0) {
  #1
  for (i in seq_len(nrow(df_priorities_clim_temp_m))) {
    #2
    print(paste("i = ", i))
    print(paste("crit = ", df_priorities_clim_temp_m[i, 4]))
    for (j in seq_len(nrow(df_growth_stages_req_temp))) {
      #3
      print(paste("j = ", j))
      period_name <- as.character(df_growth_stages_req_temp[j, 1])
      print(paste0("m period_name = ", as.character(period_name)))
      if (sum(df_priorities_clim_temp_m[i, 'phen_stage'] == period_name, na.rm = TRUE) == 1) {
        #4
        if (df_priorities_clim_temp_m[i, 14] == "mean") {
          #5
          print("mean")
          assign(
            paste0(
              "rast_",
              df_priorities_clim_temp_m[i, 12],
              "_rsmp_",
              df_growth_stages_req_temp[j, 1]
            ),
            (sum(get(
              paste0("rast_", df_priorities_clim_temp_m[i, 12], "_rsmp")
            ) * get(
              paste0("rast_period_m_", df_growth_stages_req_temp[j, 1])
            )) / sum(get(
              paste0("rast_period_m_", df_growth_stages_req_temp[j, 1])
            )))
          )
        } else {
          #-5 5a
          if (df_priorities_clim_temp_m[i, 14] == "min") {
            #6
            print("min")
            assign(
              paste0(
                "rast_",
                df_priorities_clim_temp_m[i, 12],
                "_rsmp_",
                df_growth_stages_req_temp[j, 1]
              ),
              (min(get(
                paste0("rast_", df_priorities_clim_temp_m[i, 12], "_rsmp")
              ) / round(
                get(
                  paste0("rast_period_m_", df_growth_stages_req_temp[j, 1])
                )
              )))
            )
            
          } else {
            #-6 6a
            if (df_priorities_clim_temp_m[i, 14] == "max") {
              #7
              print("max")
              assign(
                paste0(
                  "rast_",
                  df_priorities_clim_temp_m[i, 12],
                  "_rsmp_",
                  df_growth_stages_req_temp[j, 1]
                ),
                (max(
                  get(
                    paste0("rast_", df_priorities_clim_temp_m[i, 12], "_rsmp")
                  ) * get(
                    paste0("rast_period_m_", df_growth_stages_req_temp[j, 1])
                  )
                ))
              )
              
            } else {
              #-7 7a
            } #-7a
          } #-6a
        } #-5a
        plot(get(
          paste0(
            "rast_",
            df_priorities_clim_temp_m[i, 12],
            "_rsmp_",
            df_growth_stages_req_temp[j, 1]
          )
        ),
        main = paste0(
          "rast_period_m_",
          as.character(df_growth_stages_req_temp[j, 1])
        ))
        
        new_col <-
          get(
            paste0(
              "rast_",
              df_priorities_clim_temp_m[i, 12],
              "_rsmp_",
              df_growth_stages_req_temp[j , 1]
            )
          ) %>% terra::extract(xy) # extract the raster values using xy points
        
        new_col <- new_col[[1]]
        
        df_irm <-
          dplyr::select(df_irm,-any_of(c(as.character(
            paste0(df_priorities_clim_temp_m[i, 3])
          )))) # remove column if name already exists
        
        df_irm <-
          mutate(df_irm,
                 !!as.character(paste0(df_priorities_clim_temp_m[i, 3])) := new_col,
                 .keep = c("all"))   # add the raster values to the df_irm tibble, this needs to be dynamic so uses the !! and := operators
      } #-4
    }
  }
}




# for dekadal temperature data

df_priorities_clim_temp_d <-
  dplyr::filter(df_priorities_clim, prec_temp == "t" &
                  temp_resolution == "d") # filter temperature criteria

if (nrow(df_priorities_clim_temp_d) > 0) {
  #1
  for (i in seq_len(nrow(df_priorities_clim_temp_d))) {
    #2
    print(paste("i = ", i))
    print(paste("crit = ", df_priorities_clim_temp_d[i, 4]))
    for (j in seq_len(nrow(df_growth_stages_req_temp))) {
      #3
      print(paste("j = ", j))
      period_name <- as.character(df_growth_stages_req_temp[j, 1])
      print(paste0("d period_name = ", as.character(period_name)))
      if (sum(df_priorities_clim_temp_d[i, 'phen_stage'] == period_name, na.rm = TRUE) == 1) {
        #4
        if (df_priorities_clim_temp_d[i, 14] == "mean") {
          #5
          print("mean")
          assign(
            paste0(
              "rast_",
              df_priorities_clim_temp_d[i, 12],
              "_rsmp_",
              df_growth_stages_req_temp[j, 1]
            ),
            (sum(get(
              paste0("rast_", df_priorities_clim_temp_d[i, 12], "_rsmp")
            ) * get(
              paste0("rast_period_d_", df_growth_stages_req_temp[j, 1])
            )) / sum(get(
              paste0("rast_period_d_", df_growth_stages_req_temp[j, 1])
            )))
          )
        } else {
          #-5 5a
          if (df_priorities_clim_temp_d[i, 14] == "min") {
            #6
            print("min")
            assign(
              paste0(
                "rast_",
                df_priorities_clim_temp_d[i, 12],
                "_rsmp_",
                df_growth_stages_req_temp[j, 1]
              ),
              (min(get(
                paste0("rast_", df_priorities_clim_temp_d[i, 12], "_rsmp")
              ) / round(
                get(
                  paste0("rast_period_d_", df_growth_stages_req_temp[j, 1])
                )
              )))
            )
            
          } else {
            #-6 6a
            if (df_priorities_clim_temp_d[i, 14] == "max") {
              #7
              print("max")
              assign(
                paste0(
                  "rast_",
                  df_priorities_clim_temp_d[i, 12],
                  "_rsmp_",
                  df_growth_stages_req_temp[j, 1]
                ),
                (max(
                  get(
                    paste0("rast_", df_priorities_clim_temp_d[i, 12], "_rsmp")
                  ) * get(
                    paste0("rast_period_d_", df_growth_stages_req_temp[j, 1])
                  )
                ))
              )
              
            } else {
              #-7 7a
            } #-7a
          } #-6a
        } #-5a
        plot(get(
          paste0(
            "rast_",
            df_priorities_clim_temp_d[i, 12],
            "_rsmp_",
            df_growth_stages_req_temp[j, 1]
          )
        ),
        main = paste0(
          "rast_period_d_",
          as.character(df_growth_stages_req_temp[j, 1])
        ))
        
        new_col <-
          get(
            paste0(
              "rast_",
              df_priorities_clim_temp_d[i, 12],
              "_rsmp_",
              df_growth_stages_req_temp[j , 1]
            )
          ) %>% terra::extract(xy) # extract the raster values using xy points
        
        new_col <- new_col[[1]]
        
        df_irm <-
          dplyr::select(df_irm,-any_of(c(as.character(
            paste0(df_priorities_clim_temp_d[i, 3])
          )))) # remove column if name already exists
        
        df_irm <-
          mutate(df_irm,
                 !!as.character(paste0(df_priorities_clim_temp_d[i, 3])) := new_col,
                 .keep = c("all"))   # add the raster values to the df_irm tibble, this needs to be dynamic so uses the !! and := operators
      } #-4
    }
  }
}

df_priorities_clim_temp <-
  rbind(df_priorities_clim_temp_m, df_priorities_clim_temp_d)

```
</div> 


## Processing soil data

### Soil texture

If soil texture is a criterion then the USDA codes are reclassified quantitatively so that the fuzzy partitions can be applied.

Soil texture classes are reclassified in with 1, corresponding to S1 in Sys _et al._ (1993, p.159), 0.5 corresponding to S2, and 0 corresponding to S3, N1, N2 in Sys _et al._. 


```{r, results='asis'}

soil_texture_filename <-
  as.character(paste("tab_data/input/usda_texture_", params$INN1, ".csv", sep = ""))

if (file.exists(here(soil_texture_filename))) {
  df_soil_texture <- read.csv(here(soil_texture_filename))
  df_soil_texture %>%
    kable(digits = 3, caption = "Soil Texture ") %>% kable_styling("striped", full_width = T) %>% print
  
  df_priorities_texture <-
    dplyr::filter(df_raster_data_soil, texture == 1) # filter temperature criteria
  # reclass using df_soil_texture table
  
  if (nrow(df_priorities_texture) > 0) {
    
    #reclassify the texture raster (ensure that it is integer)
    rast_txt_clas_rsmp <- get(paste0("rast_", df_priorities_texture[1, 12], "_rsmp")) %>% as.int() %>% classify(as.matrix(
      dplyr::select(df_soil_texture, USDA_Texture_Class, IRM_Value)
    ))
    
    #replace the texture raster in df_raster_data_soil
    text_rownum <- which(df_raster_data_soil$texture == 1)
    
    df_raster_data_soil[1, 12] <- "txt_clas"
    
    }
}

```



### Processing soil data horizons

If the criterion does not have a growth stage it is a soil property, and the values will need to be averaged, and weighted by the depth of each horizon, and possibly any other weights (e.g. Maghami Moghim, 2024). The simplest is to assume that each horizon has decreasing importance with depth, instead of applying a weight we assume that the depth of each horizon is the same - so we just calculate a simple average. Typical horizons in ISRIC data are:  

Depth             | Interval I | Interval II | Interval III | Interval IV | Interval V | Interval VI
------------------|------------|-------------|--------------|-------------|------------|-----------
Top depth (cm)    |	0          |	5          |	15          |	30          |	60         |	100
Bottom depth (cm  |	5          |	15         |	30          |	60          | 100        |	200


```{r i1_requirements_soilp02, results='asis', warning=FALSE}

# averaging the values in the sifferent horizons
# there are two methods 1) use the thickness of each layer 2) assume that each layer contributes equally

for (i in seq_len(nrow(df_raster_data_soil))) {
  cat(paste(df_raster_data_soil[i, 3], "\n", df_raster_data_soil[i, 4], "\n"))
  
  # method 1
  
  # # standard depths for interpolation
  # standard_depths <- c(0.025, 0.10, 0.225, 0.45, 0.80, 1.50)
  # 
  # # thicknesses of individual layers
  # bottom_layer <- c(0.05, 0.15, 0.30, 0.60, 1.0)
  # thickness <- diff(c(0, bottom_layer))
  # stopifnot(max(abs(
  #   bottom_layer - 0.5 *  thickness - standard_depths[1:5]
  # )) < 1.0e-6)
  # 
  # # horizon depth weighted
  # assign(
  #   paste0("rast_", df_raster_data_soil[i, 12], "_rsmp_1"),
  #   get(paste0("rast_", df_raster_data_soil[i, 12], "_rsmp")) %>% app(function(x) {
  #     sum((x * thickness) / sum(thickness))
  #   })
  # )
  # 
  # plot(get(paste0(
  #   "rast_", df_raster_data_soil[i, 12], "_rsmp_1"
  # )),
  # main = paste0("rast_", df_raster_data_soil[i, 12], "_rsmp_1"))
  # 
  # print("method 1")
  
  # method 2
  
  n_band <- dim(get(paste0("rast_", df_raster_data_soil[i, 12], "_rsmp")))[[3]]
  print(n_band)
  
  # averaged equally across horizons
  assign(
    paste0("rast_", df_raster_data_soil[i, 12], "_rsmp"),
    get(paste0("rast_", df_raster_data_soil[i, 12], "_rsmp")) %>% app(function(x) {
      sum((x) / n_band)
    })
  )
  
  plot(get(paste0(
    "rast_", df_raster_data_soil[i, 12], "_rsmp"
  )),
  main = paste0("rast_", df_raster_data_soil[i, 12], "_rsmp"))
  
  print("method 2")
}


```

<div class="fold o">   
```{r i1_requirements_soilp04, cache = TRUE, cache.whatever=params$Agg,  out.width="100%", fig.show="hold", warning=FALSE}

for (i in seq_len(nrow(df_raster_data_soil))) {
  new_col <-
    get(paste0("rast_", df_raster_data_soil[i, 12], "_rsmp")) %>% terra::extract(xy) # extract the raster values using xy points
  
  new_col <- new_col[[1]]
  
  df_irm <-
    mutate(df_irm,!!as.character(paste0(df_raster_data_soil[i, 3])) := new_col, .keep = c("all"))   # add the raster values to the df_irm tibble, this needs to be dynamic so uses the !! and := operators
  
}

```
</div>

## Add all other criteria data to the IRM spatial database


```{r}

# some criteria use the same raster data so need to get those rows from df_priorities

df_priorities_single <- inner_join(df_priorities, select(df_raster_data_single, data_file_prefix), by = "data_file_prefix")

for (i in seq_len(nrow(df_priorities_single))) {
  new_col <-
    get(paste0("rast_", df_priorities_single[i, 12], "_rsmp")) %>% terra::extract(xy) # extract the raster values using xy points
  
  new_col <- new_col[[1]]
  
  df_irm <-
    mutate(df_irm,!!as.character(paste0(df_priorities_single[i, 3])) := new_col, .keep = c("all"))   # add the raster values to the df_irm tibble, this needs to be dynamic so uses the !! and := operators
  
}

```



# Populate the IRM database

```{r }

# df_irm <-
#   data.frame(
#     "x" = c(1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5),
#     "y" = c(1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5),
#     "subdiv" = c( "one", "one", "one", "one", "one", "two", "two", "two", "two", "two", "three", "three", "three", "three", "three", "four", "four", "four", "four", "four", "five", "five", "five", "five", "five"),
#     "ba_2a" = sample(0.5:1.5, 25, replace = TRUE),
#     "ba_4a" = sample(30:200, 25, replace = TRUE),
#     "ba_4b" = sample(60:200, 25, replace = TRUE),
#     "ba_4c" = sample(60:200, 25, replace = TRUE),
#     "ba_4d" = sample(25:200, 25, replace = TRUE),
#     "ba_4e" = sample(15:25, 25, replace = TRUE),
#     "ba_4f" = sample(5:25, 25, replace = TRUE),
#     "ba_4g" = sample(5:25, 25, replace = TRUE),
#     "ba_4h" = sample(5:25, 25, replace = TRUE),
#     "ba_3c" = sample(0.75:1.5, 25, replace = TRUE),
#     "ba_3d" = sample(1:35, 25, replace = TRUE),
#     "ba_3e" = sample(50:200, 25, replace = TRUE),
#     "ba_3f" = sample(40:80, 25, replace = TRUE),
#     "ba_3g" = sample(5:20, 25, replace = TRUE),
#     "ba_3h" = sample(30:100, 25, replace = TRUE),
#     "ba_3i" = sample(5.5:9, 25, replace = TRUE),
#     "ba_3j" = sample(0.5:10, 25, replace = TRUE),
#     "ba_3k" = sample(0:1, 25, replace = TRUE),
#     "ba_3l" = sample(1800:3000, 25, replace = TRUE),
#     "ba_3m" = sample(1:23, 25, replace = TRUE),
#     "ba_3n" = sample(3.5:10, 25, replace = TRUE),
#     "se_5a" = sample(0:1, 25, replace = TRUE),
#     "se_5b" = sample(0:5, 25, replace = TRUE),
#     "se_5c" = sample(100:1000, 25, replace = TRUE),
#     "se_5d" = sample(1:10, 25, replace = TRUE),
#     "se_5e" = sample(0:1, 25, replace = TRUE),
#     "se_5f" = sample(0:5, 25, replace = TRUE),
#     "se_4d" = sample(0:1, 25, replace = TRUE),
#     "se_4e" = sample(0:2, 25, replace = TRUE),
#     "se_3c" = sample(0:1, 25, replace = TRUE),
#     "se_3d" = sample(0:5, 25, replace = TRUE),
#     "se_3e" = sample(0:5, 25, replace = TRUE)
#   )
# 
# vect <- vect(df_irm, geom=c("x", "y"), crs="+proj=longlat +datum=WGS84")
# print(vect$subdiv)
# 
# rast_mask_proj <- rast(vect, nrow=5, ncol=5)
# values(rast_mask_proj) <- 1
# plot(rast_mask_proj)
# 
# rast_subdiv <- rasterize(vect, field = "subdiv", rast_mask_proj)
# vect_subdiv <- as.polygons(rast_subdiv, values=TRUE)
# df_subdiv_area <- as.data.frame(expanse(vect_subdiv, unit="ha"))
# df_subdiv_area <- cbind(df_subdiv_area, as.data.frame(vect_subdiv))
# names(df_subdiv_area) <- c("ha","subdiv")
# 
# max_area <- max(df_subdiv_area)
#   
# vect_subdiv <- setValues(vect_subdiv, c(1:5))
# names(vect_subdiv) <- c("subdiv")
# 
# 
# ggplot()+
#   geom_spatvector(data = vect_subdiv, aes(fill = subdiv))+
#   geom_spatvector_text(data = vect_subdiv, aes(label = subdiv))
# 
# df_irm <- select(df_irm, -subdiv)

```


# Evaluate base data level rules



```{r }

# join to original table using the criterion name

df_leaves_data <-
  left_join(df_leaves_criterion,
            df_priorities,
            by = c("rulebase_number"))

```



```{r more tests, time_it = TRUE, results = "asis"}

# Function to populate a list of proposition and conclusion levels

prop_conc <- function(df_leaves_row) {
  if (!is.na(df_leaves_row["prop_level_3"])) {
    # for those criteria with three proposition values
    prop_levels <-
      as.character(df_leaves_row[c("prop_level_1", "prop_level_2", "prop_level_3")])
    conc_levels <-
      df_leaves_row[c("conclusion_1", "conclusion_2", "conclusion_3")]
  } else {
    # for those criteria with two proposition values
    prop_levels <-
      as.character(df_leaves_row[c("prop_level_1", "prop_level_2")])
    conc_levels <- df_leaves_row[c("conclusion_1", "conclusion_2")]
  }
  
  return(list(prop_levels = prop_levels, conc_levels = conc_levels))
}

result_list <- list()

cat("\n\n\n")
cat("## Fuzzy Partitions\n") # add headings
cat("\n\n\n")
  
  
# Main function
apply(df_leaves_data, 1, function(df_leaves_row) {

  # Calculate the value list within the main function
  prop_conc_list <- prop_conc(df_leaves_row)
  prop_levels <- prop_conc_list$prop_levels
  conc_levels <- prop_conc_list$conc_levels
  conc_suffixes <- lapply(conc_levels, function(x)
    substr(x, 1, 1))
  
  cross_points <-
    as.numeric(c(df_leaves_row["threshold"], ifelse(!is.na(df_leaves_row["threshold2"]), df_leaves_row["threshold2"], NA)))
  
  cross_points <- cross_points[!is.na(cross_points)]
  
  trans_width <-
    as.numeric(c(as.numeric(df_leaves_row["width"]), ifelse(
      !is.na(as.numeric(df_leaves_row["width2"])), as.numeric(df_leaves_row["width2"]), NA
    )))
  
  trans_width <- trans_width[!is.na(trans_width)]
  
  cat("\n\n\n")
  cat("###", df_leaves_row[["criterion"]], "\n") # add headings
  cat("\n\n\n")
      
  plot_xlim <-
    as.numeric(c((as.numeric(df_leaves_row["threshold"]) - as.numeric(df_leaves_row["width"])), (as.numeric(df_leaves_row["threshold"]) + as.numeric(df_leaves_row["width"]))))
  
  # construct the fuzzy partition
  assign(
    paste0("fp_", as.character(df_leaves_row["rulebase_number"])),
    LinearFuzzyPartition(
      level = prop_levels,
      crossoverPoint = cross_points,
      transitionWidth = trans_width
    ),
    .GlobalEnv
  )
  
  # construct the fuzzy partition plot
  plot_fp <- plot(
    get(paste0("fp_", as.character(df_leaves_row["rulebase_number"]))),
    xlim = plot_xlim,
    xlab = as.character(df_leaves_row["criterion"]),
    title = "fuzzy partition"
  )
  
  # print the fuzzy partition plot
  print(plot_fp)
  
  # construct the rule bases
  # set the proposition name
  
  Prop_name <-
    paste0(as.character(df_leaves_row["rulebase_number"]))
  
  # set the conclusion name
  Conc_name <-
    paste0(as.character(df_leaves_row["rulebase_number"]),
           "_o")
  
  # thanks to https://stackoverflow.com/questions/45741498/add-column-in-tibble-with-variable-column-name for the following dynamic assignment of variable names in a tibble
  
  # set the proposition values
  df_prop <- tibble(!!Prop_name := c(prop_levels))
  # set the conclusion values
  df_conc <- tibble(!!Conc_name := c(conc_levels))
  
  # new proposition and conclusion class objects are made here
  new_prop <- new("Proposition", table = df_prop)
  new_conc <- new("Conclusion", table = df_conc)
  
  assign(paste0("rb_",
                as.character(df_leaves_row["rulebase_number"])),
         RuleBase(new_prop, new_conc),
         .GlobalEnv)
  
  print(get(paste0("rb_",
                   as.character(df_leaves_row["rulebase_number"]))))
  
  # apply the fuzzy partitions to the data
  
  # first construct the predict function with all arguments as text
  
  x <- paste0(
    "predict(rb_",
    as.character(df_leaves_row["rulebase_number"]),
    ", newdata = df_irm,",
    as.character(df_leaves_row["rulebase_number"]),
    "=",
    "fp_",
    as.character(df_leaves_row["rulebase_number"]),
    ")"
  )
  
  assign(paste0("fpm_",
                as.character(df_leaves_row["rulebase_number"])), eval(parse(text = x)), .GlobalEnv)
  #print(conc_levels[1])
  
  # Define a function to print each element
  #print_element <- function(x) {
  #  print(x)
  #}
  
  
  # Function to get the membership values of the fuzzy partition matrix for each conclusion value
  # this only works when nested in main function
  
  fpm_values <- function(conc_value) {
    
  fpm_name <-
     paste0("fpm_", df_leaves_row["rulebase_number"], "$", conc_value)
    #print(fpm_name)
    conc_col_name <-
      paste0(df_leaves_row["rulebase_number"], "_", substr(conc_value, 1, 1))
    #print(paste0("suffix = _", substr(conc_value, 1, 1)))
    x <- paste0("getMembership(", fpm_name, ")")
    #print(x)
    #print(eval(parse(text = x)))
    
    # this works
     #result_list <<-
    #   c(result_list, setNames(list(eval(parse(
    #     text = x
    #   ))), conc_col_name))
     
     # construct the fuzzy partition
  assign(paste("result_list"),
     c(result_list, setNames(list(eval(parse(
         text = x
       ))), conc_col_name)),
    .GlobalEnv
  )
    cat(conc_col_name)
    #return(result_list)
  }
  
  # apply the fpm_values to the list of conclusion levels and generate a list of values (result_list)
  lapply(unique(conc_levels), fpm_values)
  #print("done 2")
  #return(result_list)
  
})


# Convert the result list to a data frame
result_df <- data.frame(matrix(unlist(result_list), ncol = length(result_list), byrow = FALSE))
colnames(result_df) <- names(result_list)

# Bind the result data frame to the original data frame
df_irm <- cbind(df_irm, result_df)

# Print the updated data frame
#print(df_irm)
cat("\n\n\n")
cat("## Evaluate Rules\n") # add headings
cat("\n\n\n")


# Plot function for evaluated fuzzy partition using main data frame - rowwise across criteria
apply(df_leaves_data, 1, function(df_leaves_row) {
  
  cat("\n\n\n")
  cat("###", df_leaves_row[["criterion"]], "\n") # add headings
  cat("\n\n\n")
  
  prop_conc_list <- prop_conc(df_leaves_row)
  conc_levels <- prop_conc_list$conc_levels
  conc_suffixes <- lapply(conc_levels, function(x)
    substr(x, 1, 1))
  
  # Function to print each conclusion value - per unique object in list of conclusion values
  # this only works when nested in print function
  
  plot_fpm <- function(conc_value) {
    conc_col_name <-
      paste0(df_leaves_row["rulebase_number"], "_", substr(conc_value, 1, 1))
    fpm_conc_var <- c(conc_col_name, "x" , "y")
    fpm_conc_name <- conc_value

    # spatialise the results
    sf_fpm <- df_irm %>%
      dplyr::select(unlist(as.character(noquote(fpm_conc_var)))) %>%
      na.omit() %>%
      st_as_sf(coords = c("x", "y")) %>% na.omit()
    
    # rasterize
    rast_fpm <-  rasterize(sf_fpm, rast_mask_proj, fpm_conc_var[[1]]) 
    
    # give the rast sensible names
    names(rast_fpm) <- fpm_conc_name
    
    # plot rast using title
    #plot_conc <- 
    rast_fpm %>% plot(breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1),
                axes = F, main = paste0(conc_col_name, "  membership")) 
    cat(conc_col_name)
    
    }
  
  # apply the plot_fpm to the list of conclusion levels and generate plots
  lapply(unique(conc_levels), plot_fpm)
  
  #print("done 4")
  #return(plot_fpm)

})

```

# Higher-level rule base evaluation

Each row in each higher-level df is a rule base stack

For each row in each higher-level df starting with lowest level (e.g. 6)

Join to lower-level criteria to give joined df

1) Get the lower-level rule bases (1 entry per row in joined df)
2) Construct the list of lower-level rule bases (1 entry per row in joined df)
3) Construct the list of lower-level fuzzy partitions
4) Get the conclusion values of the lower-level rule bases (multiple per row in joined df)
5) Use the weights, number of lower-level rule bases and conclusion values of the lower-level rule bases to determine the number of rules (1 per joined df)
6) Use the weights (if any) to define the higher-level rule base conclusions (multiple per joined df)
7) Make a new proposition object (1 per joined df)
8) Make a new conclusion object 1 per joined df)
9) Create a new rule base (1 per joined df)
10) Add to the list of previous rule bases (1 list per joined df)
11) Evaluate the new rule base (and stack) (per joined df)
12) Add results to df_irm (per joined df)
13) Plot results (per joined df)


### Function to construct the new rule base - ALL

Logic:

1) How many lower rule bases
2) Get conclusions from lower rule bases
3) multiply conclusions by weights (if required)


``` {r  }

fn_create_rb <- function(lower_conc_values, weights, rb_conc_name) {
  
  # Create conc_options default
    conc_options <- c("suboptimal", "suboptimal", "optimal")
    c_o <- "ba"
    
  # Check if the text string is present in lower_conc_values
  if (any(grepl("good",lower_conc_values))) {
    conc_options <- c("poor", "moderate", "good")
    c_o <- "sef"
    }
  
  cat(paste("lower_conc_values =", lower_conc_values, "\n"))
  n <- length(lower_conc_values)
  weights[is.na(weights)] <- (1/n) # replace NA values in weights with values that sum to 1
  
  rb <- reduce(lower_conc_values, crossing) %>% unique() # added 09/03/2024
  n_rb <- nrow(rb)
  cat(paste("str(rb) =", str(rb), "\n"))
  cat(paste("Number of rules =", n_rb, "\n"))
  
  #rb[,] <- apply(rb, function(x) type.convert(as.character(x), as.is = TRUE))
  
  rb_integer <- rb %>%
    mutate(across(
      where(is.character),
      ~ case_when(. == "poor" ~ -1,
                  . == "suboptimal" ~ -1,
                  . == "moderate" ~ 0,
                  . == "good"  ~ 1,
                  . == "optimal" ~ 1,
                  TRUE ~ NA_integer_),
      .names = "{col}_integer"
    ))  %>% select(-where(is.character)) %>% drop()
  
  # Display the modified data frame
 
  cat(paste("str(rb_integer) =", str(rb_integer), "\n"))
  cat(paste("Weights =", weights, "\n"))
  cat(paste("Possible Conclusions =", conc_options, "\n"))
  
  rb_integer_weighted <- sweep(rb_integer, 2, weights, `*`)
  rb_integer_weighted$conc <- rowSums(rb_integer_weighted, na.rm = TRUE)
  rb_integer_weighted <- cbind(rb, rb_integer_weighted)
  
  if (c_o == "sef") {
    rb_integer_weighted$conclusion <- 
    ifelse(
      rb_integer_weighted$conc <= (-1 / 3),
      conc_options[1],
      ifelse(
        rb_integer_weighted$conc <= (1 / 3),
        conc_options[2],
        conc_options[3]
      )
    )
  } else {
    rb_integer_weighted$conclusion <-
      ifelse(rb_integer_weighted$conc < 1,
           conc_options[2],
           conc_options[3])
  }

  
  cat(paste("str(rb_integer_weighted) =", str(rb_integer_weighted), "\n"))
  names(rb_integer_weighted)[names(rb_integer_weighted)=="conclusion"] <- rb_conc_name
  cat(paste("str(rb_integer_weighted) =", str(rb_integer_weighted), "\n"))
   
    # new proposition object is made here
  prop <- new("Proposition", table = rb %>% select(where(is.character)))
  # new conclusion object is made here
  conc <- new("Conclusion", table = select(rb_integer_weighted, {{ rb_conc_name }}))
  # create a rule base
  rulebase <- RuleBase(prop, conc) %>% print()
  
  return_list <- list(rulebase, conc)

  return(return_list)
}


``` 

### Function to get all previous fuzzy partition names

Logic:

1) Does the row of the one-to-many df have data
If yes:
A2)  get fp name using rulebase number
A3)  append the fp name to the fp_list for the one-to-many df
If no:
B2) this row has an existing fp_list - get fp_list
B3) append this list to the fp_list for the one-to-many df

return the fp_list for the one-to-many df

``` {r  }

fn_fill_fp_list <- function(df_one_many) {
  
  fp_list <- list() #initialise list
  df_one_many_data <-
    dplyr::filter(df_one_many, !is.na(data_file_prefix)) # get rows that have a fuzzy partition
  df_one_many_nodata <-
    dplyr::filter(df_one_many, is.na(data_file_prefix)) # get rows that have a fuzzy partition
  
  print(paste("nrow data = ", nrow(df_one_many_data)))
  
  if (nrow(df_one_many_data) > 0) {
    fp_prefix <- "fp_"
    df_one_many_data$fp <-
      paste(fp_prefix, df_one_many_data$rulebase_number.y, sep = "")
    str(df_one_many_data)
    fp_list <-
      append(fp_list, list(
        paste(
          df_one_many_data$rulebase_number.y,
          " = ",
          df_one_many_data$fp
        )
      ))
    fp_list <- as.list(unlist(fp_list))
  }
  
  print(paste("nrow no data = ", nrow(df_one_many_nodata)))
  
  if (nrow(df_one_many_nodata) > 0) {
    for (i in 1:nrow(df_one_many_nodata)){
    fp_list <-
      append(fp_list, get(
        paste0("fp_",
          df_one_many_nodata$rulebase_number.y[i],
          "_list")
      ))
  }}
  
  return(fp_list)
}

``` 

### Function to get all previous rule base names

Logic:

1) Does the row of the one-to-many df have data
If yes:
A2)  get rb name using rulebase number
A3)  append the rb name to a rule base list for the one-to-many df
If no:
B2) this row has an existing rule base stack - get the rule base stack list
B3) append this rule base stack list to the rule base list for the one-to-many df

return the rule base list for the one-to-many df

``` {r  }

fn_fill_rb_list <- function(df_one_many) {
  
  rb_list <- list() #initialise list
  df_one_many_data <-
    dplyr::filter(df_one_many, !is.na(data_file_prefix)) # get rows that have a fuzzy partition
  df_one_many_nodata <-
    dplyr::filter(df_one_many, is.na(data_file_prefix)) # get rows that have a fuzzy partition
  
  print(paste("nrow data = ", nrow(df_one_many_data)))
  
  if (nrow(df_one_many_data) > 0) {
    # rb_prefix <- "rb_"
    # df_one_many_data$rb <-
    #   paste(rb_prefix, df_one_many_data$rulebase_number.y, sep = "")
    # str(df_one_many_data)
    rb_list <-
      append(rb_list, list(
        paste(df_one_many_data$rb
        )
      ))
    rb_list <- as.list(unlist(rb_list))
  }
  
  print(paste("nrow no data = ", nrow(df_one_many_nodata)))
  
  if (nrow(df_one_many_nodata) > 0) {
    for (i in 1:nrow(df_one_many_nodata)) {
      print(paste0("rb_list_",
                   df_one_many_nodata$rulebase_number.y[i]))
      rb_list <-
        append(rb_list, get(
          paste0("rb_list_",
                 df_one_many_nodata$rulebase_number.y[i])
        ))
    }
  }
  
  return(rb_list)
}


``` 


### Function to get the previous rule-base stack names

Logic:

1) Get the criteria that contribute to the higher-level rule base
2) Get the code for the suffix for use in mapping
3) If no code available use the number of the lower-level rule bases as a suffix 

return the codes/names of the contributing criteria for the one-to-many df

``` {r  }

fn_rbs_names <- function(df_one_many) {
  
  if ("mapping_code" %in% colnames(df_one_many)) {
    df_one_many <- select(df_one_many, rulebase_number.y, mapping_code)
  } else {
    df_one_many <- select(df_one_many, rulebase_number.y)
    df_one_many$mapping_code <- df_one_many$rulebase_number.y
  }
  
  rbs_names <- as.list(df_one_many)
  return(rbs_names)
}


``` 

## Get the data frames, conclusions (labels from a different list still using lapply), rule bases and fuzzy partitions for each rulebase stack - create the new rule base from the propositions and conclusions.

This uses the code from the previous chunks.

``` {r }

# function to get a list of lower level conclusions values in this format

fn_get_rb_conc <- function(list_object) {
  print(paste("rb list_object =" , list_object))
  rb_list_object <- get(paste(list_object))
  #print(rb_list_object)
  #str(rb_list_object)
  lower_conc_table <-
    rb_list_object@conclusion@table # gets the tibble of values
  return(lower_conc_table)
}

fn_get_rb_prop <- function(list_object) {
  print(paste("rb list_object =" , list_object))
  rb_list_object <- get(paste(list_object))
  #print(rb_list_object)
  #str(rb_list_object)
  lower_prop_table <-
    rb_list_object@proposition@table # gets the tibble of values
  return(lower_prop_table)
}

``` 

``` {r , results = 'asis' }

# inverse join df_leaves_data to df_priorities

df_rulebases <-
  anti_join(df_priorities,
            df_leaves_data,
            by = 'rulebase_number',
            copy = FALSE)

#  join df_rulebases to hierarchies_new

# first split hierarchies_new based on hierarchy level

# get highest level

hierarchy_level_max <- max(unique(hierarchies_new$level_number))
print(paste("Highest hierarchy level = ", hierarchy_level_max))

# initialise FAO limits raster list
list_rast_clas_FAO_cat <- list()

# initialise FAO limits raster list
list_rast_limits_max_FAO <- list()
       

# for loop to run through all hierarchy levels from biggest to smallest
for (i in hierarchy_level_max:1) {
  cat(paste0('\nLevel', i, "\n"))
  
  # join to the rulebases
  assign(paste0("df_hierarchy_", i),
         inner_join(
           select(df_rulebases, rulebase_number, conclusion_1, conclusion_2, conclusion_3),
           dplyr::filter(select(
             hierarchies_new, level_number, paste0('level', i)
           ), level_number == i),
           by = c('rulebase_number' = paste0('level', i))
         ))
  
  # if no data move to next
  if (nrow(get(paste0("df_hierarchy_", i)) != 0)) {
    print(paste0('Level', i, " has higher rule bases"))
    
    #Custom function to perform one-to-many join for each row and evaluate rule base
    eval_rule_base <- function(row) {
      
      # conc_options <-
      #   c(row[["conclusion_1"]], row[["conclusion_2"]], row[["conclusion_3"]])
      # print(conc_options)
      # print(paste("conc_options = ", conc_options))
      
      df_row <- data.frame(rulebase_number = row[["rulebase_number"]])
      df_one_many <-
        left_join(
          df_row,
          df_priorities,
          by = c('rulebase_number' = 'rulebase_stack'),
          keep = TRUE
        )
      
      cat("\n\n\n")
      cat("##", unique(df_one_many[["stack"]]), "\n")
      cat("\n\n\n")
      conc_name <- unique(df_one_many[["rulebase_stack"]])
      
      cat("Stack = ", df_one_many[["rulebase_stack"]], df_one_many[["stack"]])
      cat("Criterion = ", df_one_many[["criterion"]])
      cat("conc_name = ", conc_name)
      
      
      ### GET OR ADD TO THE FUZZY PARTITION LIST ###
      
      fp_list <- fn_fill_fp_list(df_one_many) # function gets the fp list
      
      assign(paste0("fp_", conc_name, "_list"),
             fp_list,
             .GlobalEnv) # make a globally available named list
      
      ### GET WEIGHTS ###
      
      weights <- df_one_many$weight
      weights_glob <<- weights
      print(weights)
      
      ### CONSTRUCT THE NEW RULE BASE ###    
      
      rb_prefix <- "rb_"
      df_one_many$rb <-
        paste(rb_prefix, df_one_many$rulebase_number.y, sep = "")

      lower_rb <- df_one_many$rb      # get the rule bases
      # get and print the lower rule bases to ensure that these are available
      print(paste("lower_rb = ", lower_rb))
      str(lower_rb)
      lower_rb_glob <<-
        lower_rb      # save to global env for debugging
      
      lower_rb_concs <- lapply(lower_rb, fn_get_rb_conc)
      lower_rb_concs_glob <<- (lower_rb_concs)      
      lower_rb_props <- lapply(lower_rb, fn_get_rb_prop)
      lower_rb_props_glob <<- (lower_rb_props) 
       
      # print(paste("str(lower_rb_concs) =", str(lower_rb_concs)))
      # print(paste("lower_rb_concs =", lower_rb_concs))

      results_rb  <- fn_create_rb(lower_rb_concs, weights, conc_name)
      str(results_rb)
      result_rb <- unlist(results_rb[[1]])
      print(result_rb)
      result_rb_conc <- unlist(results_rb[[2]])
      print(result_rb_conc)

                  
      assign(paste0("rb_",conc_name), result_rb, .GlobalEnv)
      
      
      ### GET OR ADD TO THE RULE BASE STACK ###
      
      rb_list <- fn_fill_rb_list(df_one_many)
      rb_list <-  append(rb_list, paste0("rb_", conc_name))
      rb_list_glob <<- rb_list
      print(rb_list)   
      
      assign(paste0("rb_list_", conc_name), rb_list,
             .GlobalEnv) # convert to rule base list

      newList <- list("df" = df_one_many, "fp" = fp_list , "rb" = result_rb, rbs = rb_list)

      
 
      
      # print(get(paste0("rb_list_", conc_name)))
      # str(get(paste0("rb_list_", conc_name)))
      
      # # create the rule base stack from the list
      x <-
        paste("stack(", gsub(",$", "", paste0(
          get(paste0("rb_list_", conc_name)), sep = ",", collapse = ""
        )), ")")
      
      print(x)
      
      assign(paste0("rbs_", conc_name), eval(parse(text = x)),
             .GlobalEnv)
      #print(get(paste0("rbs_", conc_name)))
      
      # # evaluate the rule base stack
      
      w <-
        paste0("predict(",
              "rbs_",
              conc_name,
              ", newdata = df_irm,",
              gsub(",$", "", paste0(
                fp_list, sep = ",", collapse = ""
              )),
              ")")
      print(w)
      assign(paste0("fpm_", conc_name), eval(parse(text = w)),
             .GlobalEnv)

      
      # columns defined by conclusions to rule base
      
      fpm_colnames <<- pull(distinct(result_rb_conc@table))
      
      print(fpm_colnames)
      
      for (j in 1:length(fpm_colnames)) {
        
      col_suffix <-   substr( fpm_colnames[[j]] , start = 1 , stop = 1 )
      print(col_suffix)
      
      mem_text <- paste0("getMembership(","fpm_", conc_name,"$", fpm_colnames[[j]],")")
      print(mem_text)
      membership <- eval(parse(text = mem_text))
      
      df_irm <<-
        mutate(df_irm,!!as.character(paste0(conc_name, "_", col_suffix)) := membership, .keep = c("all"))
        
      }
      
      rasterize_plot_fpm <-
        function(n,
                 fpm_conc_var,
                 fpm_conc_name,
                 df_data,
                 fpm_plot_title) {
          df_plot <- df_data %>%
            dplyr::select(unlist(as.character(noquote(fpm_conc_var)))) %>%
            na.omit %>%
            st_as_sf(coords = c("x", "y"))
          
          # initialise the dB raster brick using the first layer
          rast_plot <-
            rasterize(df_plot, rast_mask_proj, fpm_conc_var[[1]]) #%>% brick   # SpatRasters don't need to be bricks
          
          # in a loop add subsequent layers to the dB SpatRaster starting from the second layer
          for (k in 2:n) {
            rast_plot <-
              rast(list(rast_plot, rasterize(df_plot, rast_mask_proj, field = fpm_conc_var[[k]])))
          }
          
          # give the dB layers sensible names
          names(rast_plot) <- fpm_conc_name
          
          # plot all the layers in facets
          ggplot() +
            geom_spatraster(data = rast_plot, na.rm = TRUE) +
            scale_fill_stepsn(
              na.value = "transparent",
              n.breaks = 10,
              colours = hcl.colors(palette = "Greens 3", 10, rev = T),
              guide = "legend"
            ) +
            facet_wrap( ~ lyr) +
            labs(title = fpm_plot_title) +
            theme(
              panel.grid.major.x = element_blank(),
              panel.grid.minor.x = element_blank(),
              axis.title.x = element_blank(),
              axis.title.y = element_blank(),
              strip.background = element_rect(fill=NA),
              panel.background = element_rect(fill=NA))
        }
      
      n = length(fpm_colnames)
      fpm_conc_var <- c()
      for (j in 1:length(fpm_colnames)) {
        col_suffix <-   substr(fpm_colnames[[j]] , start = 1 , stop = 1)
        fpm_conc_var <-
          c(fpm_conc_var, paste0(conc_name, "_", col_suffix))
      }
      
      fpm_conc_var <-    c(fpm_conc_var, "x" , "y")
      fpm_conc_name <- fpm_colnames
      fpm_plot_title <-    paste(unique(df_one_many[["stack"]]))
      
      
      plot_fpm <-
      rasterize_plot_fpm(n, fpm_conc_var, fpm_conc_name, df_irm, fpm_plot_title)
      
      print(plot_fpm)
    # #
    

      
      # Classified maps
      cat(
        "\n\n\n
Classified maps are currently produced for Adoption, Biophysical Aptitude and for Socio-economic Feasibility.

Problem 1): Currently, the evaluation of the chunks that create these maps is determined by a parameter in the chunk options. That parameter is either TRUE or FALSE depending on the name of the rule base stack in the priorities table.

Problem 2): The number of classes for the biophysical aptitude limitations maps is also dependent on the number of types of limitations possible (e.g. soil fertility).

Logic: For the two top hierarchy level rule-bases produce classified maps with limitations based on lower-level inputs.\n\n\n")
      
      
      classify_maps_FAO <-
        function(n,
                 fpm_conc_var,
                 fpm_conc_name,
                 df_data,
                 fpm_plot_title) {
          df_plot <- df_data %>%
            dplyr::select(unlist(as.character(noquote(fpm_conc_var)))) %>%
            na.omit %>%
            st_as_sf(coords = c("x", "y"))

          #cat("str(df_one_many) = ", str(df_one_many),"\n")
          stack_code <<- unique(df_one_many[['rulebase_stack']])
          cat("stack_code = ", stack_code,"\n")
       
          if ("optimal" %in% fpm_conc_name) { # biophysical aptitude criteria
            
            cat("OPTIMAL")           
            print(match("optimal",fpm_conc_name))
            opt_match <- match("optimal",fpm_conc_name)
            opt_match_glob <<- opt_match
            
            #create raster using the 'optimal' layer
            rast_plot <-
              rasterize(df_plot, rast_mask_proj, fpm_conc_var[[opt_match]])
            names(rast_plot) <- fpm_conc_name[[opt_match]]
            
          } else {
            # socio-economic feasibility criteria
            
            cat("GOOD")
            match_set <- c("good", "high")
            print(match(match_set, fpm_conc_name))
            good_match <- max(match(match_set, fpm_conc_name), na.rm = T)
            good_match_glob <<- good_match
            
            #create raster using the 'good/high' layer
            rast_plot <-
              rasterize(df_plot, rast_mask_proj, fpm_conc_var[[good_match]])
            names(rast_plot) <- fpm_conc_name[[good_match]]
            
            if (length(fpm_conc_name) == 3) {# only run when a moderate conclusion
            
            cat("MODERATE")  
            match_set <- c("moderate")
            print(match(match_set, fpm_conc_name))
            moderate_match <- max(match(match_set, fpm_conc_name), na.rm = T)
            moderate_match_glob <<- moderate_match
            
            #create raster using the 'good/high' layer
            rast_plot2 <- rasterize(df_plot, rast_mask_proj, fpm_conc_var[[moderate_match]])
            names(rast_plot2) <- fpm_conc_name[[moderate_match]]
            
            #*Optimal*
            # High feasibility has a value of 1.
            # Moderate feasibility has a value of 0.5.
            
            rast_plot <- sum(rast_plot, (rast_plot2 * 0.5))
            }
          }
          
          rast_plot_name <- names(rast_plot)
          
          # plot the 'optimal' layer
          ggplot() +
            geom_spatraster(data = rast_plot, na.rm = TRUE, aes(fill = rast_plot_name)) +
            scale_fill_stepsn(
              na.value = "transparent",
              n.breaks = 10,
              colours = hcl.colors(palette = "Greens 3", 10, rev = T),
              guide = "legend"
            ) +
            #facet_wrap(~ lyr) +
            labs(title = fpm_plot_title) +
            theme(
              panel.grid.major.x = element_blank(),
              panel.grid.minor.x = element_blank(),
              axis.title.x = element_blank(),
              axis.title.y = element_blank(),
              strip.background = element_rect(fill = NA),
              panel.background = element_rect(fill = NA)
            )
          
          # classify values and export
          ## from-to-becomes
          # classify the optimal values into five groups
          # all values >= 0 and <= 0.25 become N2, etc.
          v_clas_fao <- c(-Inf, 0.25, 5,
                        0.25, 0.4, 4,
                        0.4, 0.6, 3,
                        0.6, 0.85, 2,
                        0.85, Inf, 1)
          m_clas_fao <- matrix(v_clas_fao, ncol = 3, byrow = TRUE)
          rast_clas_fao_bin <-
            classify(rast_plot, m_clas_fao, include.lowest = TRUE)
          rast_clas_fao_cat <- rast_clas_fao_bin
          df_clas_fao <-
            data.frame(id = 1:5, FAO = c("S1", "S2", "S3", "N1", "N2"))
          levels(rast_clas_fao_cat) <- df_clas_fao
          rast_clas_fao_brick <-
            rast(list(rast_plot, rast_clas_fao_bin, rast_clas_fao_cat))
          names(rast_clas_fao_brick) <- c(rast_plot_name, 'bin', 'FAO')
          output_geotiff(rast_clas_fao_brick, paste0("FAO_", stack_code, "_", params$INN1))
          
          # export class and optimal value as polygon
          vect_clas_fao_cat <-
            as.polygons(rast_clas_fao_cat, dissolve = T)
          
          # vect_filename <-
          #   as.character(paste("spatial_data/output/1class_clas1_", params$INN1, ".shp"))
          # writeVector(vect_clas_fao_cat, here(vect_filename), overwrite = TRUE)
          
          assign(paste0("rast_clas_fao_cat", fpm_plot_title),
                 rast_clas_fao_cat,
                 .GlobalEnv)
          
          list_rast_clas_FAO_cat <<-
            append(list_rast_clas_FAO_cat,
                   paste0("rast_clas_fao_cat", fpm_plot_title))
                  
                            
         g <-  ggplot() +
            geom_spatraster(data = rast_clas_fao_cat, na.rm = TRUE, aes(fill = FAO)) +
            scale_fill_manual(
              name = paste0("FAO\n", fpm_plot_title, "\n", params$INN1),
              na.value = "transparent",
              values = c(
                S1 = rgb(51, 160, 44, maxColorValue = 255),
                S2 = rgb(178, 223, 138, maxColorValue = 255),
                S3 = rgb(255, 255, 153, maxColorValue = 255),
                N1 = rgb(255, 127, 0, maxColorValue = 255),
                N2 = rgb(227, 26, 28, maxColorValue = 255)
              )
            )
         g
         add_subdiv_proj_simple_plot(g)

                  
        } # end of classify_maps_FAO function
      # ### TO BE DONE 17/02/2024 ### START
      cat(paste("\nDEBUG1 START\n\n"))
      
      classify_maps_limits <- function(n, fpm_conc_var, fpm_conc_name, df_data, fpm_plot_title) {
        
        # what are the previous level inputs - the rows in the one-to-many table
        
        rbs_names <- fn_rbs_names(df_one_many)[[1]]
    
        lower_rb_var_1 <- lapply(rbs_names, function(x) paste0(x, "_s"))
        lower_rb_var_2 <- lapply(rbs_names, function(x) paste0(x, "_p"))
        lower_rb_var_3 <- lapply(rbs_names, function(x) paste0(x, "_l"))
        lower_rb_var_4 <- lapply(rbs_names, function(x) paste0(x, "_m"))
        lower_rb_var   <- c(lower_rb_var_1, lower_rb_var_2, lower_rb_var_3, lower_rb_var_4)
        
        mapping_code_suffixes <- (fn_rbs_names(df_one_many)[[2]]) 

        limits_var <- c(unlist(as.character(noquote(fpm_conc_var))), unlist(lower_rb_var))
        cat("limits_var")
        print(limits_var)
       
        # df_limits <- df_data %>%
        #     dplyr::select(any_of(limits_var)) %>%
        #     na.omit %>%
        #     st_as_sf(coords = c("x", "y"))
        
        df_limits <- df_data %>%
            dplyr::select(any_of(limits_var))
        
        cat("df_limits")
        str(df_limits)
        
        # get a combined score for each contributing rule base
        
        cat("\n\ncombined score\n\n")
                # get a weighted score
        
        cat("\n\nweighted score\n\n")
        
  
        
        w_score_list <- list() # initialise list
        
        for (l in 1:length(rbs_names)) {
          cat("rbs_names[[l]] = ", rbs_names[[l]],"\n")
          cat("weights[[l]] = ", weights[[l]],"\n")
          
          if (is.na(weights[[l]])) {weights[[l]] <- 1/length(rbs_names)}
          
          score_var <- paste0(rbs_names[[l]], "_score")
          w_score_var <- paste0(rbs_names[[l]], "_w_score")
          w_score_list <- append(w_score_list, w_score_var)
          
          expr_w_score <- parse(text = paste0(weights[[l]]," * ", score_var)) # weighted score
          
          
          if (paste0(rbs_names[[l]], "_m") %in% colnames(df_limits)) {
            print("moderate")# there is a moderate conclusion
            expr_score <- parse(text = paste0(rbs_names[[l]], "_p + (", rbs_names[[l]], "_m * 0.5)" ))
            df_limits <- mutate(
              df_limits,
              !!score_var := eval(expr_score), !!w_score_var := eval(expr_w_score), .keep = c("all"))
            str(df_limits)
            
          } else {
            if (paste0(rbs_names[[l]], "_p") %in% colnames(df_limits)) {
              print("poor") # there is a poor conclusion
              expr_score <-
                parse(text = paste0(rbs_names[[l]], "_p"))
              df_limits <- mutate(df_limits,!!score_var := eval(expr_score), !!w_score_var := eval(expr_w_score),  .keep = c("all"))
              str(df_limits)
            } else {
              if (paste0(rbs_names[[l]], "_l") %in% colnames(df_limits)) {
                print("low") # there is a low conclusion
                expr_score <-
                parse(text = paste0(rbs_names[[l]], "_l"))
              df_limits <- mutate(df_limits,!!score_var := eval(expr_score), !!w_score_var := eval(expr_w_score),  .keep = c("all"))
              str(df_limits)
              } else {
                print("suboptimal") # there is a suboptimal conclusion
                expr_score <-
                parse(text = paste0(rbs_names[[l]], "_s"))
              df_limits <- mutate(df_limits,!!score_var := eval(expr_score), !!w_score_var := eval(expr_w_score),  .keep = c("all"))
              str(df_limits)
              }
            }
          }
        }
        
        # get the max value
        cat("\n\nmax value\n\n")
        df_limits_w_score <<-
          select(df_limits, unlist(w_score_list)) %>%
          mutate(across(everything(), ~ replace_na(.x, 0)))
        
        cat("DEBUG LIMITS df_limits_w_score")
        #print(df_limits_w_score)
        
        w_score_max_index <-
          matrix(apply(df_limits_w_score, 1 , which.max))
        value = integer(0)

        map_code <- mapping_code_suffixes[w_score_max_index]
        w_score_max_name <-
          matrix(colnames(df_limits_w_score)[apply(df_limits_w_score, 1 , which.max)])
        
        df_map_code <-
          data.frame(
            w_score_max_index = w_score_max_index[, 1],
            w_score_max_name = w_score_max_name[, 1],
            map_code = map_code
          )
        
        rast_filename <-
          as.character(paste0(
            "spatial_data/output/FAO_",
            stack_code,
            "_",
            params$INN1,
            ".tif"
          ))
        
        rast_clas_fao_brick <- rast(here(rast_filename)) # get the FAO raster
        cat("rast_clas_fao_brick \n")
        print(rast_clas_fao_brick)
        
        str(df_map_code)
        df_limits_max <- cbind(df_limits, df_map_code)
        # str(df_limits_max)
        
        v_limits_max <- df_limits_max %>% na.omit %>% st_as_sf(coords = c("x", "y"))
        # str(v_limits_max)
        
        rast_limits_max <- rasterize(v_limits_max, rast_mask_proj, field = "w_score_max_index")
        cat("rast_limits_max \n")
        print(rast_limits_max)
        
        cat("df_map_code \n")
        str(df_map_code)
                
        cat("df_map_code_cat \n")
        df_map_code_cat <- unique(df_map_code[c("w_score_max_index", "map_code")])
        str(df_map_code_cat)
        
        levels(rast_limits_max) <- df_map_code_cat
        
        rast_limits_max_FAO <-  concats(rast_clas_fao_brick$FAO, rast_limits_max)
        names(rast_limits_max_FAO) <- c('FAO_limit')
        cat("rast_limits_max_FAO \n")
        print(rast_limits_max_FAO)
        
        # how many suitability levels?
        FAO_levels <- unique(rast_clas_fao_brick$FAO)
        cat(nrow(FAO_levels), " FAO_levels \n")
        print(str(FAO_levels))
        
        # how many limits levels?
        FAO_limit_levels <- unique(droplevels(pull(rast_limits_max_FAO, FAO_limit)))
        cat(length(FAO_limit_levels), " FAO_limit_levels \n")
        print(str(FAO_limit_levels))
        
        # how many limits levels?
        df_FAO_limit_levels <-
          unique(rast_limits_max_FAO$FAO_limit)
        cat(nrow(df_FAO_limit_levels), " df_FAO_limit_levels \n")
        print(str(df_FAO_limit_levels))
        
        df_FAO_limit_levels <- df_FAO_limit_levels %>%
          mutate(value = case_when(
            grepl("S1", FAO_limit) ~ 1,
            grepl("S2", FAO_limit) ~ 0.875,
            grepl("S3", FAO_limit) ~ 0.75,
            grepl("N1", FAO_limit) ~ 0.625,
            grepl("N2", FAO_limit) ~ 0.5,
            TRUE ~ 0.5  # Default value if none of the conditions are met
          ))
        
        df_FAO_limit_levels <- df_FAO_limit_levels %>%
          mutate(
            hue = case_when(
              grepl("BA", FAO_limit) ~ 0.25,
              grepl("SE", FAO_limit) ~ 0.75,
              grepl("LU", FAO_limit) ~ 0,
              grepl("Cl", FAO_limit) ~ 0.2,
              grepl("Ls", FAO_limit) ~ 0.4,
              grepl("SF", FAO_limit) ~ 0.6,
              grepl("SP", FAO_limit) ~ 0.8,
              grepl("MA", FAO_limit) ~ 0.5,
              grepl("FP", FAO_limit) ~ 1,
              TRUE ~ 0.9  # Default value if none of the conditions are met
            )
          )
        
        df_FAO_limit_levels <-
          df_FAO_limit_levels %>%
          mutate(
            sat = case_when(
              grepl("BA", FAO_limit) ~ 0.8,
              grepl("SE", FAO_limit) ~ 0.8,
              grepl("LU", FAO_limit) ~ 0.5,
              grepl("Cl", FAO_limit) ~ 0.5,
              grepl("Ls", FAO_limit) ~ 0.5,
              grepl("SF", FAO_limit) ~ 0.5,
              grepl("SP", FAO_limit) ~ 0.5,
              grepl("MA", FAO_limit) ~ 0.5,
              grepl("FP", FAO_limit) ~ 0.5,
              TRUE ~ 0.4  # Default value if none of the conditions are met
            )
          )
        
        df_FAO_limit_levels$hsv <-
          paste(
            "(",
            df_FAO_limit_levels$hue, ",",
            df_FAO_limit_levels$sat, ",",
            df_FAO_limit_levels$value,
            ")")
        
        # Create a new column using the apply function
        df_FAO_limit_levels$hsv_eval <-
          apply(df_FAO_limit_levels[, c("hue", "sat", "value")], 1, function(row) {
            hsv(row[1], row[2], row[3])
          })
        
        cat(nrow(df_FAO_limit_levels), " df_FAO_limit_levels \n")
        print(str(df_FAO_limit_levels))

        test_FAO_limits <- pull(df_FAO_limit_levels, FAO_limit)
        test_FAO_colours <- pull(df_FAO_limit_levels, hsv_eval)
        
        # save raster
        assign(paste0("rast_limits_max_FAO_", fpm_plot_title), rast_limits_max_FAO,
             .GlobalEnv)
        
        # add raster to list
        list_rast_limits_max_FAO <<- append(list_rast_limits_max_FAO, paste0("rast_limits_max_FAO_", fpm_plot_title))

        ggplot() +
          geom_spatraster(data = rast_limits_max_FAO, aes(fill = FAO_limit), na.rm = TRUE) +
          scale_fill_manual(
            name = paste0("FAO limitations\n", fpm_plot_title, "\n", params$INN1),
            na.value = "transparent",
            breaks = test_FAO_limits,
            values = test_FAO_colours
          )
          

        
      }# end of classify_maps_limits function
      
        ### TO BE DONE 19/02/2024 ### END    
      #
      
      if (i < 4) {
        #only run for top two levels
        map_classified_FAO <-
          classify_maps_FAO(n, fpm_conc_var, fpm_conc_name, df_irm, fpm_plot_title)
        print(map_classified_FAO)
      }
      
      if (i < 4) {
        map_classified_limits <-
          classify_maps_limits(n, fpm_conc_var, fpm_conc_name, df_irm, fpm_plot_title)
        print(map_classified_limits)
      }
      
      cat(paste("\nDEBUG1 END\n\n"))
      
      

      
      
      cat(paste("\nEND \n\n"))
            
      return(newList)
      
     }
    
    # Apply the rule base evaluation function to each row of df1
    assign(paste0("df_one_many_", i),
           apply(get(paste0("df_hierarchy_", i)), 1, eval_rule_base))
    
    

    
    
    
    
  }
}


```


# Subdiv statistics

This section gets the statistics for each sub-division, taking into account the dynamically created limitations for adoption, suitability and feasibility.


The existing function expects arguments showing:

1) the number of maps to produce - one per class (of whatever output)
2) a vector of the variables (classes) that need to be mapped (1 and 2 are linked and 1 is not really necessary)
3) a palette of colours with the same number of colours as classes - these are 

The palettes in the current IRM do not match with the any of the colours used in the classified maps.
Instead they are just a distinct colour.

The variables and colour palette names are currently hard coded. The names of the palettes are from the ggplot2 package but derive from colorbrewer, all palettes are sequential. There are 18 named sequential palettes, they can be referenced by name or as an index from the list.

The index works as long as the values do not exceed 18, so need to wrap.

## Area

### FAO Classes

```{r , results = 'asis'}

# create a list of valid names of colorbrewer palettes for sequential data
palettes <-
  c("Blues",
    "YlGn",
    "Greys",
    "Oranges",
    "YlOrRd"
  )


# loop through the FAO class rasters created above

for (i in 1:length(list_rast_clas_FAO_cat))   {
  # get the name of the criteria from the raster name - this is used in the plotting
  subdiv_criteria_name <- list_rast_clas_FAO_cat[i]
  subdiv_criteria_name <-
    sub(paste0(".*", "fao_cat"), "", subdiv_criteria_name)
  
  # get the raster for which statistics are derived for each limitation
  rast_to_plot <- get(paste0(list_rast_clas_FAO_cat[i]))
  
  # get the cellsize for each raster
  rast_to_plot_cellsize <- cellSize(rast_to_plot, unit = "ha")
  
  
  # extract the raster class to a data frame using the subdivisions
  df_extr <-
    terra::extract(rast_to_plot, vect_subdiv, na.rm = TRUE, ID = T, weights = T)
  
    # extract the raster cellsize to a data frame using the subdivisions
  df_extr_cellsize <-
    terra::extract(rast_to_plot_cellsize, vect_subdiv, na.rm = TRUE, ID = T, weights = T)
  
  df_extr <- mutate(df_extr, df_extr_cellsize)
  
   # summarise the class for each subdivision raster ID
  df_extr_summary <- df_extr %>%
    group_by(ID) %>%
    count(FAO, wt = (area * weight), .drop = FALSE)
  
  # join the summary data frame to the original subdivision data spatvector
  vect_subdiv_extr <<-
    left_join(vect_subdiv, df_extr_summary, by = 'ID')
  
  # loop through each existing class type 
  for (class_type in unique(vect_subdiv_extr$FAO)) {
    
    # Get the current iteration number
    j <- match(class_type, unique(vect_subdiv_extr$FAO))

    # get the palette using the iteration number
    colour_index <- j
    colour_index_mod <- (colour_index %% 18)
    colour_index_mod <-
      ifelse(colour_index_mod == 0, 18, colour_index_mod)
    result <- palettes[colour_index_mod]
    
    # Filter the joined data for the current limitation
    filtered_data <-
      vect_subdiv_extr[vect_subdiv_extr$FAO == class_type,]
    #print(filtered_data)
    
    if (nrow(filtered_data) == 0) {next} 
    cat("\n\n\n")
    cat("###", subdiv_criteria_name, "\n") # add headings
    cat("\n\n\n")
  
    # Create a ggplot for count value per subdivision for the current class type using the palette from above
    subdiv_plot <- ggplot() +
      geom_spatvector(data = filtered_data, aes(group = params$SUBDIV1, fill = n)) +
      labs(
        title = paste(subdiv_criteria_name, "\nClass = ", class_type),
        fill = "Area (ha)"
      ) +
      scale_fill_distiller(
        type = "seq",
        palette = result,
        direction = 1,
        limits = c(0, max_area),
        guide = "legend", labels = comma
      ) 
    
    print(subdiv_plot)
  }
}  


```

### FAO Limitations

```{r, results = 'asis'}

# create a list of valid names of colorbrewer palettes for sequential data
palettes <-
  c(
    "Blues",
    "BuGn",
    "BuPu",
    "GnBu",
    "Greens",
    "Greys",
    "Oranges",
    "OrRd",
    "PuBu",
    "PuBuGn",
    "PuRd",
    "Purples",
    "RdPu",
    "Reds",
    "YlGn",
    "YlGnBu",
    "YlOrBr",
    "YlOrRd"
  )


# loop through the limitation rasters created above

for (i in 1:length(list_rast_limits_max_FAO))   {
  # get the name of the criteria from the raster name - this is used in the plotting
  subdiv_criteria_name <- list_rast_limits_max_FAO[i]
  subdiv_criteria_name <-
    sub(paste0(".*", "FAO_"), "", subdiv_criteria_name)
  
  # get the raster for which statistics are derived for each limitation
  rast_to_plot <- get(paste0(list_rast_limits_max_FAO[i]))
  
  # get the cellsize for each raster
  rast_to_plot_cellsize <- cellSize(rast_to_plot, unit = "ha")
  
  
  # extract the raster limitations to a data frame using the subdivisions
  df_extr <-
    terra::extract(rast_to_plot, vect_subdiv, na.rm = TRUE, ID = T, weights = T)
  
    # extract the raster cellsize to a data frame using the subdivisions
  df_extr_cellsize <-
    terra::extract(rast_to_plot_cellsize, vect_subdiv, na.rm = TRUE, ID = T, weights = T)
  
  df_extr <- mutate(df_extr, df_extr_cellsize)
  
   # summarise the limitations for each subdivision raster ID
  df_extr_summary <- df_extr %>%
    group_by(ID) %>%
    count(FAO_limit, wt = (area * weight), .drop = FALSE)
  
  # join the summary data frame to the original subdivision data spatvector
  vect_subdiv_extr <<-
    left_join(vect_subdiv, df_extr_summary, by = 'ID')
  
  # loop through each existing limitation type 
  for (limitation_type in unique(vect_subdiv_extr$FAO_limit)) {
    
    # Get the current iteration number
    j <- match(limitation_type, unique(vect_subdiv_extr$FAO_limit))

    # get the palette using the iteration number
    colour_index <- j
    colour_index_mod <- (colour_index %% 18)
    colour_index_mod <-
      ifelse(colour_index_mod == 0, 18, colour_index_mod)
    result <- palettes[colour_index_mod]
    
    # Filter the joined data for the current limitation
    filtered_data <-
      vect_subdiv_extr[vect_subdiv_extr$FAO_limit == limitation_type,]
    #print(filtered_data)
    if (nrow(filtered_data) == 0) {next} 
    
    cat("\n\n\n")
    cat("###", subdiv_criteria_name, "\n") # add headings
    cat("\n\n\n")
    
    # Create a ggplot for count value per subdivision for the current limitation type using the palette from above
    subdiv_plot <- ggplot() +
      geom_spatvector(data = filtered_data, aes(group = params$SUBDIV1, fill = n)) +
      labs(
        title = paste(subdiv_criteria_name, "\nLimit = ", limitation_type),
        fill = "Area (ha)"
      ) +
      scale_fill_distiller(
        type = "seq",
        palette = result,
        direction = 1,
        limits = c(0, max_area),
        guide = "legend", labels = comma
      ) 
    
    print(subdiv_plot)
  }
}  


```

## Percentage

### FAO Classes

```{r, results = 'asis'}

# create a list of valid names of colorbrewer palettes for sequential data
palettes <-
  c("Blues",
    "YlGn",
    "Greys",
    "Oranges",
    "YlOrRd"
  )


# loop through the FAO class rasters created above

for (i in 1:length(list_rast_clas_FAO_cat))   {
  # get the name of the criteria from the raster name - this is used in the plotting
  subdiv_criteria_name <- list_rast_clas_FAO_cat[i]
  subdiv_criteria_name <-
    sub(paste0(".*", "fao_cat"), "", subdiv_criteria_name)
  
  # get the raster for which statistics are derived for each limitation
  rast_to_plot <- get(paste0(list_rast_clas_FAO_cat[i]))
  
  # get the cellsize for each raster
  rast_to_plot_cellsize <- cellSize(rast_to_plot, unit = "ha")
  
  
  # extract the raster class to a data frame using the subdivisions
  df_extr <-
    terra::extract(rast_to_plot, vect_subdiv, na.rm = TRUE, ID = T, weights = T)
  
    # extract the raster cellsize to a data frame using the subdivisions
  df_extr_cellsize <-
    terra::extract(rast_to_plot_cellsize, vect_subdiv, na.rm = TRUE, ID = T, weights = T)
  
  df_extr <- mutate(df_extr, df_extr_cellsize)
  
   # summarise the class for each subdivision raster ID
  df_extr_summary <- df_extr %>%
    group_by(ID) %>%
    count(FAO, wt = (area * weight), .drop = FALSE)
  
  # join the summary data frame to the original subdivision data spatvector
  vect_subdiv_extr <<-
    left_join(vect_subdiv, df_extr_summary, by = 'ID')
  
   # join the summary data frame to the subdivision area data frame
  vect_subdiv_extr <<-
    left_join(vect_subdiv_extr, df_subdiv_area, by = 'ID') 
  
  vect_subdiv_extr <<-
    mutate(vect_subdiv_extr, area_pc = (n/ha)*100) 
  
  # loop through each existing class type 
  for (class_type in unique(vect_subdiv_extr$FAO)) {
    
    # Get the current iteration number
    j <- match(class_type, unique(vect_subdiv_extr$FAO))

    # get the palette using the iteration number
    colour_index <- j
    colour_index_mod <- (colour_index %% 18)
    colour_index_mod <-
      ifelse(colour_index_mod == 0, 18, colour_index_mod)
    result <- palettes[colour_index_mod]
    
    # Filter the joined data for the current limitation
    filtered_data <-
      vect_subdiv_extr[vect_subdiv_extr$FAO == class_type,]
    #print(filtered_data)
    if (nrow(filtered_data) == 0) {next} 
    
    cat("\n\n\n")
    cat("###", subdiv_criteria_name, "\n") # add headings
    cat("\n\n\n")
    
    # Create a ggplot for count value per subdivision for the current class type using the palette from above
    
    filtered_data_global <<- filtered_data
      
    subdiv_plot <- ggplot() +
      geom_spatvector(data = filtered_data, aes(group = params$SUBDIV1, fill = area_pc)) +
      labs(
        title = paste(subdiv_criteria_name, "\nClass = ", class_type),
        fill = "Area (%)"
      ) +
      scale_fill_distiller(
        type = "seq",
        palette = result,
        direction = 1,
        limits = c(0, 101),
        guide = "legend", labels = comma
      ) 
    
    print(subdiv_plot)
  }
}  


```

### FAO Limitations

```{r, results = 'asis'}

# create a list of valid names of colorbrewer palettes for sequential data
palettes <-
  c(
    "Blues",
    "BuGn",
    "BuPu",
    "GnBu",
    "Greens",
    "Greys",
    "Oranges",
    "OrRd",
    "PuBu",
    "PuBuGn",
    "PuRd",
    "Purples",
    "RdPu",
    "Reds",
    "YlGn",
    "YlGnBu",
    "YlOrBr",
    "YlOrRd"
  )


# loop through the limitation rasters created above

for (i in 1:length(list_rast_limits_max_FAO))   {
  # get the name of the criteria from the raster name - this is used in the plotting
  subdiv_criteria_name <- list_rast_limits_max_FAO[i]
  subdiv_criteria_name <-
    sub(paste0(".*", "FAO_"), "", subdiv_criteria_name)
  
  # get the raster for which statistics are derived for each limitation
  rast_to_plot <- get(paste0(list_rast_limits_max_FAO[i]))
  
  # get the cellsize for each raster
  rast_to_plot_cellsize <- cellSize(rast_to_plot, unit = "ha")
  
  
  # extract the raster limitations to a data frame using the subdivisions
  df_extr <-
    terra::extract(rast_to_plot, vect_subdiv, na.rm = TRUE, ID = T, weights = T)
  
    # extract the raster cellsize to a data frame using the subdivisions
  df_extr_cellsize <-
    terra::extract(rast_to_plot_cellsize, vect_subdiv, na.rm = TRUE, ID = T, weights =T)
  
  df_extr <- mutate(df_extr, df_extr_cellsize)
  
   # summarise the limitations for each subdivision raster ID
  df_extr_summary <- df_extr %>%
    group_by(ID) %>%
    count(FAO_limit, wt = (area * weight), .drop = FALSE)
  
  # join the summary data frame to the original subdivision data spatvector
  vect_subdiv_extr <<-
    left_join(vect_subdiv, df_extr_summary, by = 'ID')
  
  # join the summary data frame to the subdivision area data frame
  vect_subdiv_extr <<-
    left_join(vect_subdiv_extr, df_subdiv_area, by = 'ID')
  
  vect_subdiv_extr <<-
    mutate(vect_subdiv_extr, area_pc = (n / ha) * 100)  
  
  # loop through each existing limitation type 
  for (limitation_type in unique(vect_subdiv_extr$FAO_limit)) {
    
    # Get the current iteration number
    j <- match(limitation_type, unique(vect_subdiv_extr$FAO_limit))

    # get the palette using the iteration number
    colour_index <- j
    colour_index_mod <- (colour_index %% 18)
    colour_index_mod <-
      ifelse(colour_index_mod == 0, 18, colour_index_mod)
    result <- palettes[colour_index_mod]
    
    # Filter the joined data for the current limitation
    filtered_data <-
      vect_subdiv_extr[vect_subdiv_extr$FAO_limit == limitation_type,]
    #print(filtered_data)
    if (nrow(filtered_data) == 0) {next} 
    
    cat("\n\n\n")
    cat("###", subdiv_criteria_name, "\n") # add headings
    cat("\n\n\n")
    
    # Create a ggplot for count value per subdivision for the current limitation type using the palette from above
    subdiv_plot <- ggplot() +
      geom_spatvector(data = filtered_data, aes(group = params$SUBDIV1, fill = area_pc)) +
      labs(
        title = paste(subdiv_criteria_name, "\nLimit = ", limitation_type),
        fill = "Area (%)"
      ) +
      scale_fill_distiller(
        type = "seq",
        palette = result,
        direction = 1,
        limits = c(0, 101),
        guide = "legend", labels = comma
      ) 
    
    print(subdiv_plot)
  }
}  


```

# Calculate yields and production

## Yield proportion

The IRM script already calculates the optimality of the individual criteria as well as the climatic, landscape, soil fertility and soil physical properties groups of criteria.

The first method of calculating yield will calculate the product of the optimality of selected criteria.

<div class="fold o"> 
```{r i1_calc_yield_1, cache = TRUE, cache.whatever=params$Agg,  out.width="100%", include = TRUE, echo=FALSE, message=FALSE, warning=FALSE}

# get the criteria that contribute to yield

df_yield_rb_1 <- dplyr::select(df_priorities, "rulebase_number","criterion","yield") %>% dplyr::filter(!is.na(yield))

df_yield_rb_1 %>% kable(digits = 3) %>% kable_styling("striped", full_width = T)  %>%  scroll_box(height = "500px")
# make an expression using the rule base numbers

yield_expr <- paste("df_irm$yieldpc <- (")

for (i in seq(from = 1,
              to = nrow(df_yield_rb_1),
              by = 1)) {
  yield_expr <- paste0(yield_expr, "df_irm$" , as.character(df_yield_rb_1[i, 1]), "_o * ")
  
}
yield_expr <- paste(yield_expr, " 100)")
yield_expr

# evaluate the expression
eval(str2expression(yield_expr))
# str(df_irm$yieldpc)
if (summarise(df_irm, Average = mean(yieldpc, na.rm = T)) > 0) {

# df_irm <- dplyr::select(df_irm,-yield)

vect_yieldpc <- select(df_irm, x, y, yieldpc) %>% na.omit %>% vect(geom = c("x", "y"))

rast_yieldpc <- rasterize(vect_yieldpc, rast_mask_proj, field="yieldpc")
names(rast_yieldpc) <- c('yieldpc')

# export
output_geotiff(rast_yieldpc, paste0("yieldpc_", params$INN1))

#  dy <- rast_yield %>%
#    as.data.frame(xy = TRUE) %>%
#    na.omit

  
  gy <- ggplot() +
    geom_spatraster(data = rast_yieldpc, aes(fill = yieldpc)) +
    scale_fill_stepsn(
      paste0("Yield % \n", params$INN1),
      n.breaks = 10,
      limits = c(0, 100),
      colours = hcl.colors(palette = "Greens", 10, rev = TRUE),
      guide = "legend",  na.value = "transparent"
    ) +
#    scale_x_continuous(
#      name = "",
#      labels = function(x) {
#        1.0e-3 * x
#      }
#    ) +
#    scale_y_continuous(
#      name = "",
#      labels = function(x) {
#        1.0e-3 * x
#      }
#    ) +
    coord_sf()
  
  gy2 <- add_subdiv_proj_simple_plot(gy)
gy2
}
```
</div>

## Calculate yield

The IRM script converts yield proportion to yield using the yield values for sole crop or intercrop.

<div class="fold o"> 
```{r i1_calc_yield_2, cache = TRUE, cache.whatever=params$Agg, out.width="100%", include = TRUE, echo=FALSE, message=FALSE, warning=FALSE}

# get the criteria that contribute to yield

filename_yield <-
  as.character(paste("tab_data/input/yield_", params$INN1, ".csv", sep = ""))
df_yield_values <- read.csv(here(filename_yield), na.strings = c("NA"))

df_yield_values %>% kable(digits = 3) %>% kable_styling("striped", full_width = T)  %>%  scroll_box(height = "100px")


if (params$INN2 == "NA") {
  df_irm$yield <- df_irm$yieldpc / 100 * df_yield_values$YW
  cat("Sole crop yield")
} else {
  if (params$SYS == "comparison") {
    df_irm$yield <- df_irm$yieldpc / 100 * df_yield_values$YW
    cat("Sole crop 1 yield (comparison)")
  } else {
    if (params$SYS == "intercrop") {
      df_irm$yield <- df_irm$yieldpc / 100 * df_yield_values$YI
      cat("Intercrop 1 yield")
    } else {
      if (params$SYS == "rotation") {
        df_irm$yield <- df_irm$yieldpc / 100 * df_yield_values$YW
        cat("Rotation crop 1 yield")
      }
    }
  }
}

if (summarise(df_irm, Average = mean(yield, na.rm = T)) > 0) {
  
  vect_yield <-
    select(df_irm, x, y, yield) %>% na.omit %>% vect(geom = c("x", "y"))
  
  rast_yield <- rasterize(vect_yield, rast_mask_proj, field = "yield")
  names(rast_yield) <-  c('yield')

# export
output_geotiff(rast_yield, paste0("yield_", params$INN1))

#dyd <- dByd %>%
#  as.data.frame(xy = TRUE) %>%
#  na.omit


gyd <- ggplot() +
  geom_spatraster(data = rast_yield, aes(fill = yield)) +
  scale_fill_stepsn(
    paste0("Yield (kg/ha) \n", params$INN1),
    n.breaks = 10,
    colours = hcl.colors(palette = "OrRd", 10, rev = TRUE),
    guide = "legend",
    labels = comma,  na.value = "transparent"
  ) +
#  scale_x_continuous(
#    name = "",
#    labels = function(x) {
#      1.0e-3 * x
#    }
#  ) +
#  scale_y_continuous(
#    name = "",
#    labels = function(x) {
#      1.0e-3 * x
#    }
#  ) +
  coord_sf()

  gyd2 <- add_subdiv_proj_simple_plot(gyd)
gyd2
}
```
</div>

## Calculate production

The IRM script converts yield proportion to production using the yield values for sole crop or intercrop.

<div class="fold o">
```{r i1_calc_yield_3, cache = TRUE, cache.whatever=params$Agg, out.width="100%", include = TRUE, echo=FALSE, message=FALSE, warning=FALSE}

# get the criteria that contribute to yield

#yield_filename <-
#  as.character(paste("tab_data/input/yield_", params$INN1, ".csv", sep = ""))
#yield_tab <- read.csv(here(yield_filename), na.strings = c("NA"))

#yield_tab %>% kable(digits = 3) %>% kable_styling("striped", full_width = T)  %>%  scroll_box(height = "150px")

df_irm$production <- df_irm$yieldpc *  Stat_factor_ha

if (summarise(df_irm, Average = mean(production, na.rm = T)) > 0) {
  vect_production <-
    select(df_irm, x, y, production) %>% na.omit %>% vect(geom = c("x", "y"))
  
  rast_production <-
    rasterize(vect_production, rast_mask_proj, field = "production")
  names(rast_production) <- c('production')
  
  # export
  output_geotiff(rast_production, paste0("production_", params$INN1))
  
  #  dp <- dBp %>%
  #    as.data.frame(xy = TRUE) %>%
  #    na.omit
  
  gp <- ggplot() +
    geom_spatraster(data = rast_production, aes(fill = production)) +
    scale_fill_stepsn(
      paste0("Production (kg) \n", params$INN1),
      n.breaks = 10,
      colours = hcl.colors(palette = "BuPu", 10, rev = TRUE),
      guide = "legend",
      labels = comma,
      na.value = "transparent"
    ) +
#    scale_x_continuous(
#      name = "",
#      labels = function(x) {
#        1.0e-3 * x
#      }
#    ) +
#    scale_y_continuous(
#      name = "",
#      labels = function(x) {
#        1.0e-3 * x
#      }
#    ) +
    coord_sf()
  
  gp2 <- add_subdiv_proj_simple_plot(gp)
  gp2
}
```
</div>
 







